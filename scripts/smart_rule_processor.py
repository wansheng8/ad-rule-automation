#!/usr/bin/env python3
"""
æ™ºèƒ½å¹¿å‘Šè§„åˆ™å¤„ç†ç³»ç»Ÿ - TXTé…ç½®ç‰ˆ
ç”Ÿæˆ Adblock.txt, hosts.txt, Domains.txt ä¸‰ç§æ ¼å¼çš„è§„åˆ™
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥configæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.settings import get_all_sources, Config
except ImportError as e:
    print(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")
    print("âš ï¸  è¯·ç¡®ä¿ config/settings.py å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
    sys.exit(1)

import re
import time
import json
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Set, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import requests
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
except ImportError:
    print("é”™è¯¯ï¼šè¯·å…ˆå®‰è£…ä¾èµ–ï¼špip install requests")
    sys.exit(1)

def get_shanghai_time() -> datetime:
    """è·å–å½“å‰ä¸Šæµ·æ—¶é—´ (UTC+8)"""
    try:
        shanghai_tz = timezone(timedelta(hours=8))
        utc_now = datetime.now(timezone.utc)
        return utc_now.astimezone(shanghai_tz)
    except Exception:
        return datetime.now()

def get_time_string() -> str:
    """è·å–æ ¼å¼åŒ–çš„ä¸Šæµ·æ—¶é—´å­—ç¬¦ä¸²"""
    return get_shanghai_time().strftime('%Y-%m-%d %H:%M:%S')

class RuleFetcher:
    """è§„åˆ™è·å–å™¨"""
    
    def __init__(self):
        self.session = self._create_session()
        self.stats = {
            'total_sources': 0,
            'successful': 0,
            'failed': 0,
            'source_details': {}
        }
        
    def _create_session(self):
        """åˆ›å»ºHTTPä¼šè¯"""
        session = requests.Session()
        
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        session.headers.update({
            'User-Agent': 'AdRuleAutomation/3.0',
            'Accept': 'text/plain, */*',
        })
        
        return session
    
    def fetch_url(self, url: str) -> Tuple[bool, Optional[str], int]:
        """è·å–å•ä¸ªURLçš„å†…å®¹"""
        try:
            start_time = time.time()
            timeout = getattr(Config, 'REQUEST_TIMEOUT', 30)
            response = self.session.get(url, timeout=timeout)
            response.raise_for_status()
            
            content = response.text
            lines = len(content.split('\n'))
            elapsed = time.time() - start_time
            
            self.stats['successful'] += 1
            self.stats['source_details'][url] = {
                'status': 'success',
                'lines': lines,
                'time_seconds': round(elapsed, 2),
                'size_bytes': len(content.encode('utf-8'))
            }
            
            return True, content, lines
        except Exception as e:
            self.stats['failed'] += 1
            self.stats['source_details'][url] = {
                'status': 'failed',
                'error': str(e)
            }
            return False, None, 0

class RuleProcessor:
    """è§„åˆ™å¤„ç†å™¨ - æ”¯æŒä¸‰æ ¼å¼è¾“å‡º"""
    
    def __init__(self):
        self.fetcher = RuleFetcher()
        self.adblock_rules = set()
        self.hosts_entries = set()
        self.domains_set = set()
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½è§„åˆ™æº
        try:
            all_sources = get_all_sources()
            if all_sources:
                self.rule_sources = all_sources
            else:
                self.rule_sources = [
                    "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt",
                    "https://easylist.to/easylist/easylist.txt",
                    "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",
                    "https://someonewhocares.org/hosts/zero/hosts",
                ]
                print("âš ï¸  é…ç½®æ–‡ä»¶ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™æº")
        except Exception as e:
            print(f"âŒ åŠ è½½è§„åˆ™æºé…ç½®å¤±è´¥: {e}")
            self.rule_sources = [
                "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt",
                "https://easylist.to/easylist/easylist.txt",
                "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",
                "https://someonewhocares.org/hosts/zero/hosts",
            ]
        
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_duration': 0,
            'rules_processed': 0,
            'rules_by_source': {},
            'update_status': 'no_change'
        }
    
    def process_rules(self) -> bool:
        """å¤„ç†æ‰€æœ‰è§„åˆ™"""
        print("=" * 60)
        print("ğŸ”„ å¼€å§‹å¤„ç†å¹¿å‘Šè§„åˆ™")
        print(f"ğŸ“… å½“å‰ä¸Šæµ·æ—¶é—´: {get_time_string()}")
        print(f"ğŸ“Š è§„åˆ™æºæ€»æ•°: {len(self.rule_sources)} ä¸ª")
        print("=" * 60)
        
        self.stats['start_time'] = get_time_string()
        start_timestamp = time.time()
        
        print(f"ğŸ“¥ è·å– {len(self.rule_sources)} ä¸ªè§„åˆ™æº...")
        self.fetcher.stats['total_sources'] = len(self.rule_sources)
        
        contents = {}
        max_workers = getattr(Config, 'MAX_WORKERS', 15)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {executor.submit(self.fetcher.fetch_url, url): url 
                           for url in self.rule_sources}
            
            processed = 0
            total = len(self.rule_sources)
            
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                success, content, lines = future.result()
                processed += 1
                
                if success and content:
                    contents[url] = content
                    print(f"  [{processed}/{total}] âœ… è·å–æˆåŠŸ: {url} ({lines} è¡Œ)")
                    self.stats['rules_by_source'][url] = lines
                else:
                    print(f"  [{processed}/{total}] âŒ è·å–å¤±è´¥: {url}")
        
        print(f"\nğŸ” åˆ†æè§„åˆ™å†…å®¹...")
        previous_counts = {
            'adblock': len(self.adblock_rules),
            'hosts': len(self.hosts_entries),
            'domains': len(self.domains_set)
        }
        
        for url, content in contents.items():
            self._parse_content(content, url)
        
        self.stats['rules_processed'] = len(self.adblock_rules) + len(self.hosts_entries) + len(self.domains_set)
        
        current_counts = {
            'adblock': len(self.adblock_rules),
            'hosts': len(self.hosts_entries),
            'domains': len(self.domains_set)
        }
        
        if all(count > 0 for count in current_counts.values()):
            if any(current_counts[k] != previous_counts[k] for k in current_counts):
                self.stats['update_status'] = 'updated'
            else:
                self.stats['update_status'] = 'no_change'
        else:
            self.stats['update_status'] = 'failed'
        
        print(f"\nğŸ’¾ ä¿å­˜è§„åˆ™æ–‡ä»¶...")
        success = self._save_results()
        
        elapsed_time = time.time() - start_timestamp
        self.stats['end_time'] = get_time_string()
        self.stats['total_duration'] = round(elapsed_time, 2)
        
        self._generate_detailed_stats()
        
        print("=" * 60)
        if success:
            status_emoji = "ğŸ”„" if self.stats['update_status'] == 'updated' else "â¸ï¸"
            print(f"{status_emoji} å¤„ç†å®Œæˆï¼çŠ¶æ€: {self.stats['update_status']}")
            print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
            print(f"ğŸ“Š Adblockè§„åˆ™: {current_counts['adblock']} æ¡")
            print(f"ğŸ“Š Hostsè§„åˆ™: {current_counts['hosts']} ä¸ª")
            print(f"ğŸ“Š çº¯åŸŸå: {current_counts['domains']} ä¸ª")
            print(f"ğŸ“ˆ è§„åˆ™æº: {self.fetcher.stats['successful']}æˆåŠŸ/{self.fetcher.stats['failed']}å¤±è´¥")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥")
        
        print("=" * 60)
        return success and self.stats['update_status'] != 'failed'
    
    def _parse_content(self, content: str, source_url: str):
        """è§£æè§„åˆ™å†…å®¹ï¼Œåˆ†ç¦»ä¸‰ç§æ ¼å¼"""
        lines = content.split('\n')
        counts = {'adblock': 0, 'hosts': 0, 'domains': 0}
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('!') or line.startswith('#'):
                continue
            
            # 1. è¯†åˆ«Adblock-styleè§„åˆ™
            if (line.startswith('||') and line.endswith('^')) or \
               line.startswith('|') or \
               '##' in line or \
               (line.startswith('/') and line.endswith('/')):
                if line not in self.adblock_rules:
                    self.adblock_rules.add(line)
                    counts['adblock'] += 1
            
            # 2. è¯†åˆ«Hostsè§„åˆ™
            elif re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\s+', line):
                parts = line.split()
                if len(parts) >= 2 and parts[0] in ['0.0.0.0', '127.0.0.1']:
                    rule = f"{parts[0]} {parts[1]}"
                    if rule not in self.hosts_entries:
                        self.hosts_entries.add(rule)
                        counts['hosts'] += 1
                    
                    domain = parts[1]
                    if self._is_valid_domain(domain) and domain not in self.domains_set:
                        self.domains_set.add(domain)
                        counts['domains'] += 1
            
            # 3. è¯†åˆ«çº¯åŸŸå
            elif self._is_valid_domain(line):
                if line not in self.domains_set:
                    self.domains_set.add(line)
                    counts['domains'] += 1
        
        if any(counts.values()):
            self.stats['rules_by_source'][source_url] = counts
    
    def _is_valid_domain(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åŸŸåæ ¼å¼"""
        if not text or ' ' in text or '#' in text or '!' in text:
            return False
        domain_pattern = r'^([a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}$'
        return bool(re.match(domain_pattern, text))
    
    def _save_results(self) -> bool:
        """ä¿å­˜ä¸‰ç§æ ¼å¼çš„è§„åˆ™ç»“æœ"""
        try:
            os.makedirs("dist", exist_ok=True)
            os.makedirs("stats", exist_ok=True)
            
            current_time = get_time_string()
            
            # 1. ä¿å­˜Adblockè§„åˆ™
            with open("dist/Adblock.txt", 'w', encoding='utf-8') as f:
                f.write(f"""! Adblock-style è§„åˆ™
! é€‚ç”¨äº uBlock Origin, AdGuard, Adblock Plus ç­‰æµè§ˆå™¨æ’ä»¶
! æœ€åæ›´æ–°: {current_time}
! è§„åˆ™æ€»æ•°: {len(self.adblock_rules)}
! æ›´æ–°çŠ¶æ€: {self.stats['update_status']}
! GitHub: https://github.com/wansheng8/ad-rule-automation
!

""")
                for rule in sorted(self.adblock_rules):
                    f.write(f"{rule}\n")
            print(f"  âœ… ä¿å­˜Adblockè§„åˆ™: {len(self.adblock_rules)} æ¡ -> dist/Adblock.txt")
            
            # 2. ä¿å­˜Hostsè§„åˆ™
            with open("dist/hosts.txt", 'w', encoding='utf-8') as f:
                f.write(f"""# /etc/hosts è¯­æ³•è§„åˆ™
# é€‚ç”¨äºç³»ç»Ÿhostsæ–‡ä»¶ã€Pi-holeã€AdGuard Homeç­‰
# æœ€åæ›´æ–°: {current_time}
# è§„åˆ™æ€»æ•°: {len(self.hosts_entries)}
# æ›´æ–°çŠ¶æ€: {self.stats['update_status']}
# GitHub: https://github.com/wansheng8/ad-rule-automation
#

""")
                sorted_hosts = sorted(self.hosts_entries)
                zero_hosts = [h for h in sorted_hosts if h.startswith('0.0.0.0')]
                local_hosts = [h for h in sorted_hosts if h.startswith('127.0.0.1')]
                for rule in zero_hosts + local_hosts:
                    f.write(f"{rule}\n")
            print(f"  âœ… ä¿å­˜Hostsè§„åˆ™: {len(self.hosts_entries)} ä¸ª -> dist/hosts.txt")
            
            # 3. ä¿å­˜çº¯åŸŸååˆ—è¡¨
            with open("dist/Domains.txt", 'w', encoding='utf-8') as f:
                f.write(f"""# çº¯åŸŸååˆ—è¡¨
# é€‚ç”¨äºDNSè¿‡æ»¤ã€é˜²ç«å¢™è§„åˆ™ç­‰
# æœ€åæ›´æ–°: {current_time}
# åŸŸåæ€»æ•°: {len(self.domains_set)}
# æ›´æ–°çŠ¶æ€: {self.stats['update_status']}
# GitHub: https://github.com/wansheng8/ad-rule-automation
#

""")
                for domain in sorted(self.domains_set):
                    f.write(f"{domain}\n")
            print(f"  âœ… ä¿å­˜çº¯åŸŸååˆ—è¡¨: {len(self.domains_set)} ä¸ª -> dist/Domains.txt")
            
            return True
            
        except Exception as e:
            print(f"  âŒ ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _generate_detailed_stats(self):
        """ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š"""
        try:
            timestamp = get_shanghai_time().strftime('%Y%m%d_%H%M%S')
            stats_file = f"stats/processing_stats_{timestamp}.json"
            
            detailed_stats = {
                "processing_info": {
                    "start_time": self.stats['start_time'],
                    "end_time": self.stats['end_time'],
                    "total_duration_seconds": self.stats['total_duration'],
                    "update_status": self.stats['update_status'],
                    "shanghai_timezone": True
                },
                "rules_summary": {
                    "adblock_rules": len(self.adblock_rules),
                    "hosts_entries": len(self.hosts_entries),
                    "domains": len(self.domains_set),
                    "total_processed": self.stats['rules_processed']
                },
                "sources_summary": self.fetcher.stats,
                "rules_by_source": self.stats['rules_by_source'],
                "output_files": {
                    "adblock": "dist/Adblock.txt",
                    "hosts": "dist/hosts.txt",
                    "domains": "dist/Domains.txt"
                }
            }
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_stats, f, indent=2, ensure_ascii=False)
            
            print(f"  ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {stats_file}")
            
            # ç”ŸæˆMarkdownæŠ¥å‘Š
            self._generate_markdown_report(detailed_stats, timestamp)
            
        except Exception as e:
            print(f"  âš ï¸  ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    def _generate_markdown_report(self, stats_data, timestamp):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        try:
            md_file = f"stats/report_{timestamp}.md"
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(f"# å¹¿å‘Šè§„åˆ™å¤„ç†æŠ¥å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {stats_data['processing_info']['end_time']}\n")
                f.write(f"**çŠ¶æ€**: {stats_data['processing_info']['update_status']}\n")
                f.write(f"**è¾“å‡ºæ–‡ä»¶**: [Adblock.txt](dist/Adblock.txt), [hosts.txt](dist/hosts.txt), [Domains.txt](dist/Domains.txt)\n\n")
                
                f.write(f"## å¤„ç†æ¦‚è§ˆ\n\n")
                f.write(f"- **æ€»è€—æ—¶**: {stats_data['processing_info']['total_duration_seconds']}ç§’\n")
                f.write(f"- **è§„åˆ™æº**: {stats_data['sources_summary']['successful']}æˆåŠŸ/{stats_data['sources_summary']['failed']}å¤±è´¥\n\n")
                
                f.write(f"## è§„åˆ™ç»Ÿè®¡\n\n")
                f.write(f"- **Adblockè§„åˆ™**: {stats_data['rules_summary']['adblock_rules']}æ¡\n")
                f.write(f"- **Hostsè§„åˆ™**: {stats_data['rules_summary']['hosts_entries']}ä¸ª\n")
                f.write(f"- **çº¯åŸŸå**: {stats_data['rules_summary']['domains']}ä¸ª\n")
                f.write(f"- **æ€»è®¡**: {stats_data['rules_summary']['total_processed']}æ¡è§„åˆ™\n")
            
            print(f"  ğŸ“‹ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")
        except Exception as e:
            print(f"  âš ï¸  ç”ŸæˆMarkdownæŠ¥å‘Šæ—¶å‡ºé”™: {e}")

def verify_configuration():
    """éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½"""
    try:
        print("ğŸ”§ éªŒè¯é…ç½®...")
        all_sources = get_all_sources()
        
        if not all_sources:
            print("âŒ é…ç½®æ–‡ä»¶é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è§„åˆ™æºURL")
            print("ğŸ’¡ è¯·æ£€æŸ¥ config/rule_sources.txt æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªURLï¼‰")
            return False
        
        print(f"âœ… é…ç½®éªŒè¯é€šè¿‡: ä»TXTæ–‡ä»¶åŠ è½½äº† {len(all_sources)} ä¸ªè§„åˆ™æº")
        
        print("ğŸ“‹ è§„åˆ™æºç¤ºä¾‹:")
        for i, url in enumerate(all_sources[:3], 1):
            from urllib.parse import urlparse
            domain = urlparse(url).netloc
            print(f"  {i}. [{domain}]")
        if len(all_sources) > 3:
            print(f"  ... è¿˜æœ‰ {len(all_sources) - 3} ä¸ªè§„åˆ™æº")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– æ™ºèƒ½å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ (TXTé…ç½®ç‰ˆ)")
    print("=" * 60)
    
    if not verify_configuration():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¿è¡Œ")
        return 1
    
    processor = RuleProcessor()
    
    try:
        success = processor.process_rules()
        return 0 if success else 1
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        return 130
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
