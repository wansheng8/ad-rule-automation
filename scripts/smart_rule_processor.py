#!/usr/bin/env python3
"""
æ™ºèƒ½å¹¿å‘Šè§„åˆ™å¤„ç†ç³»ç»Ÿ - æ™ºèƒ½å»é‡ä¸ä¼˜åŒ–ç‰ˆ
ç”Ÿæˆ Adblock.txt, hosts.txt, Domains.txt ä¸‰ç§æ ¼å¼çš„è§„åˆ™ï¼Œå¸¦æ™ºèƒ½å»é‡å’Œä¼˜åŒ–
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.settings import get_all_sources, Config
except ImportError as e:
    print(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")
    print("âš ï¸  è¯·ç¡®ä¿ config/settings.py å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
    sys.exit(1)

import re
import time
import json
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Set, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict

try:
    import requests
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
except ImportError:
    print("é”™è¯¯ï¼šè¯·å…ˆå®‰è£…ä¾èµ–ï¼špip install requests")
    sys.exit(1)

def get_shanghai_time() -> datetime:
    """è·å–å½“å‰ä¸Šæµ·æ—¶é—´ (UTC+8)"""
    try:
        shanghai_tz = timezone(timedelta(hours=8))
        utc_now = datetime.now(timezone.utc)
        return utc_now.astimezone(shanghai_tz)
    except Exception:
        return datetime.now()

def get_time_string() -> str:
    """è·å–æ ¼å¼åŒ–çš„ä¸Šæµ·æ—¶é—´å­—ç¬¦ä¸²"""
    return get_shanghai_time().strftime('%Y-%m-%d %H:%M:%S')

class RuleFetcher:
    """è§„åˆ™è·å–å™¨"""
    
    def __init__(self):
        self.session = self._create_session()
        self.stats = {
            'total_sources': 0,
            'successful': 0,
            'failed': 0,
            'source_details': {}
        }
        
    def _create_session(self):
        """åˆ›å»ºHTTPä¼šè¯"""
        session = requests.Session()
        
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        session.headers.update({
            'User-Agent': 'AdRuleAutomation/4.0',
            'Accept': 'text/plain, */*',
        })
        
        return session
    
    def fetch_url(self, url: str) -> Tuple[bool, Optional[str], int]:
        """è·å–å•ä¸ªURLçš„å†…å®¹"""
        try:
            start_time = time.time()
            timeout = getattr(Config, 'REQUEST_TIMEOUT', 30)
            response = self.session.get(url, timeout=timeout)
            response.raise_for_status()
            
            content = response.text
            lines = len(content.split('\n'))
            elapsed = time.time() - start_time
            
            self.stats['successful'] += 1
            self.stats['source_details'][url] = {
                'status': 'success',
                'lines': lines,
                'time_seconds': round(elapsed, 2),
                'size_bytes': len(content.encode('utf-8'))
            }
            
            return True, content, lines
        except Exception as e:
            self.stats['failed'] += 1
            self.stats['source_details'][url] = {
                'status': 'failed',
                'error': str(e)
            }
            return False, None, 0

class RuleOptimizer:
    """è§„åˆ™ä¼˜åŒ–å™¨ - æä¾›æ™ºèƒ½å»é‡å’Œä¼˜åŒ–åŠŸèƒ½"""
    
    @staticmethod
    def deduplicate_adblock_rules(rules: Set[str]) -> Set[str]:
        """æ™ºèƒ½å»é‡Adblockè§„åˆ™"""
        if not rules:
            return set()
        
        print(f"  æ­£åœ¨å¯¹ {len(rules)} æ¡Adblockè§„åˆ™è¿›è¡Œæ™ºèƒ½å»é‡...")
        
        # 1. åŸºæœ¬å»é‡ï¼ˆåŸºäºå­—ç¬¦ä¸²å®Œå…¨åŒ¹é…ï¼‰
        unique_rules = set(rules)
        print(f"    åŸºæœ¬å»é‡å: {len(unique_rules)} æ¡")
        
        # 2. åŸŸåçº§å»é‡ï¼šæå–è§„åˆ™ä¸­çš„åŸŸåï¼Œå»é™¤é‡å¤åŸŸåçš„ä¸åŒå˜ä½“
        domain_to_rules = defaultdict(set)
        optimized_rules = set()
        removed_count = 0
        
        for rule in unique_rules:
            domain = RuleOptimizer._extract_domain_from_adblock_rule(rule)
            if domain:
                # å¦‚æœè¿™ä¸ªåŸŸåå·²ç»æœ‰è§„åˆ™äº†ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ›´é€šç”¨çš„è§„åˆ™
                existing_rules = domain_to_rules.get(domain, set())
                if existing_rules:
                    # æ£€æŸ¥æ–°è§„åˆ™æ˜¯å¦æ¯”ç°æœ‰è§„åˆ™æ›´å…·ä½“æˆ–æ›´é€šç”¨
                    should_add = True
                    for existing_rule in existing_rules:
                        # å¦‚æœæ–°è§„åˆ™æ›´é€šç”¨ï¼Œæ›¿æ¢æ—§è§„åˆ™
                        if RuleOptimizer._is_more_general_rule(rule, existing_rule):
                            optimized_rules.remove(existing_rule)
                            domain_to_rules[domain].remove(existing_rule)
                            removed_count += 1
                            break
                        # å¦‚æœæ–°è§„åˆ™æ›´å…·ä½“ï¼Œè·³è¿‡
                        elif RuleOptimizer._is_more_specific_rule(rule, existing_rule):
                            should_add = False
                            removed_count += 1
                            break
                    
                    if should_add:
                        optimized_rules.add(rule)
                        domain_to_rules[domain].add(rule)
                else:
                    optimized_rules.add(rule)
                    domain_to_rules[domain].add(rule)
            else:
                optimized_rules.add(rule)
        
        print(f"    æ™ºèƒ½å»é‡å: {len(optimized_rules)} æ¡ (ç§»é™¤äº† {removed_count} æ¡å†—ä½™è§„åˆ™)")
        return optimized_rules
    
    @staticmethod
    def _extract_domain_from_adblock_rule(rule: str) -> Optional[str]:
        """ä»Adblockè§„åˆ™ä¸­æå–åŸŸå"""
        # å¤„ç†å¸¸è§çš„Adblockè¯­æ³•
        if rule.startswith('||'):
            # ||example.com^
            match = re.match(r'^\|\|([a-zA-Z0-9.*-]+)\^', rule)
            if match:
                return match.group(1)
        elif rule.startswith('|'):
            # |https://example.com/
            match = re.match(r'^\|(?:https?://)?([a-zA-Z0-9.*-]+)', rule)
            if match:
                return match.group(1)
        elif '##' in rule:
            # example.com##selector
            parts = rule.split('##')
            if len(parts) == 2:
                return parts[0].strip()
        return None
    
    @staticmethod
    def _is_more_general_rule(rule1: str, rule2: str) -> bool:
        """æ£€æŸ¥rule1æ˜¯å¦æ¯”rule2æ›´é€šç”¨"""
        # ç®€å•çš„å¯å‘å¼è§„åˆ™ï¼šé€šé…ç¬¦æ›´å¤šæˆ–æ›´çŸ­é€šå¸¸æ›´é€šç”¨
        if '*' in rule1 and '*' not in rule2:
            return True
        if rule1.startswith('||') and not rule2.startswith('||'):
            return True
        return False
    
    @staticmethod
    def _is_more_specific_rule(rule1: str, rule2: str) -> bool:
        """æ£€æŸ¥rule1æ˜¯å¦æ¯”rule2æ›´å…·ä½“"""
        # ç›¸åçš„å¯å‘å¼
        if '*' not in rule1 and '*' in rule2:
            return True
        if not rule1.startswith('||') and rule2.startswith('||'):
            return True
        return False
    
    @staticmethod
    def deduplicate_hosts_entries(entries: Set[str]) -> Set[str]:
        """å»é‡Hostsæ¡ç›®"""
        if not entries:
            return set()
        
        print(f"  æ­£åœ¨å¯¹ {len(entries)} ä¸ªHostsæ¡ç›®è¿›è¡Œå»é‡...")
        
        # åŸºäºåŸŸåçš„å»é‡ï¼šæ¯ä¸ªåŸŸååªä¿ç•™ä¸€ä¸ªæ¡ç›®ï¼ˆä¼˜å…ˆ0.0.0.0ï¼‰
        domain_to_entry = {}
        duplicates_removed = 0
        
        for entry in entries:
            parts = entry.split()
            if len(parts) >= 2:
                ip, domain = parts[0], parts[1]
                if domain in domain_to_entry:
                    duplicates_removed += 1
                    # ä¼˜å…ˆä¿ç•™0.0.0.0è€Œä¸æ˜¯127.0.0.1
                    existing_ip = domain_to_entry[domain].split()[0]
                    if existing_ip == '127.0.0.1' and ip == '0.0.0.0':
                        domain_to_entry[domain] = entry
                else:
                    domain_to_entry[domain] = entry
        
        result = set(domain_to_entry.values())
        print(f"    Hostså»é‡å: {len(result)} ä¸ª (ç§»é™¤äº† {duplicates_removed} ä¸ªé‡å¤åŸŸå)")
        return result
    
    @staticmethod
    def deduplicate_domains(domains: Set[str]) -> Set[str]:
        """å»é‡åŸŸå"""
        if not domains:
            return set()
        
        print(f"  æ­£åœ¨å¯¹ {len(domains)} ä¸ªåŸŸåè¿›è¡Œå»é‡...")
        
        # åŸºæœ¬å»é‡
        unique_domains = set(domains)
        
        # ç§»é™¤å­åŸŸåå¦‚æœçˆ¶åŸŸåå·²å­˜åœ¨ï¼ˆå¯é€‰ï¼‰
        optimized_domains = set()
        removed_subdomains = 0
        
        for domain in sorted(unique_domains, key=len, reverse=True):
            # æ£€æŸ¥æ˜¯å¦æ˜¯å…¶ä»–åŸŸåçš„å­åŸŸå
            is_subdomain = False
            for other_domain in optimized_domains:
                if domain.endswith('.' + other_domain):
                    is_subdomain = True
                    removed_subdomains += 1
                    break
            
            if not is_subdomain:
                optimized_domains.add(domain)
        
        print(f"    åŸŸåå»é‡å: {len(optimized_domains)} ä¸ª (ç§»é™¤äº† {removed_subdomains} ä¸ªå­åŸŸå)")
        return optimized_domains

class RuleProcessor:
    """è§„åˆ™å¤„ç†å™¨ - å¢å¼ºç‰ˆï¼ŒåŒ…å«æ™ºèƒ½å»é‡"""
    
    def __init__(self):
        self.fetcher = RuleFetcher()
        self.optimizer = RuleOptimizer()
        self.adblock_rules = set()
        self.hosts_entries = set()
        self.domains_set = set()
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½è§„åˆ™æº
        try:
            all_sources = get_all_sources()
            if all_sources:
                self.rule_sources = all_sources
            else:
                self.rule_sources = [
                    "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt",
                    "https://easylist.to/easylist/easylist.txt",
                    "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",
                    "https://someonewhocares.org/hosts/zero/hosts",
                ]
                print("âš ï¸  é…ç½®æ–‡ä»¶ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™æº")
        except Exception as e:
            print(f"âŒ åŠ è½½è§„åˆ™æºé…ç½®å¤±è´¥: {e}")
            self.rule_sources = [
                "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt",
                "https://easylist.to/easylist/easylist.txt",
                "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",
                "https://someonewhocares.org/hosts/zero/hosts",
            ]
        
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_duration': 0,
            'rules_processed': 0,
            'rules_by_source': {},
            'duplicates_removed': {
                'adblock': 0,
                'hosts': 0,
                'domains': 0
            },
            'update_status': 'no_change'
        }
    
    def process_rules(self) -> bool:
        """å¤„ç†æ‰€æœ‰è§„åˆ™"""
        print("=" * 60)
        print("ğŸ”„ å¼€å§‹å¤„ç†å¹¿å‘Šè§„åˆ™ï¼ˆæ™ºèƒ½å»é‡ç‰ˆï¼‰")
        print(f"ğŸ“… å½“å‰ä¸Šæµ·æ—¶é—´: {get_time_string()}")
        print(f"ğŸ“Š è§„åˆ™æºæ€»æ•°: {len(self.rule_sources)} ä¸ª")
        print("=" * 60)
        
        self.stats['start_time'] = get_time_string()
        start_timestamp = time.time()
        
        print(f"ğŸ“¥ è·å– {len(self.rule_sources)} ä¸ªè§„åˆ™æº...")
        self.fetcher.stats['total_sources'] = len(self.rule_sources)
        
        contents = {}
        max_workers = getattr(Config, 'MAX_WORKERS', 15)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {executor.submit(self.fetcher.fetch_url, url): url 
                           for url in self.rule_sources}
            
            processed = 0
            total = len(self.rule_sources)
            
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                success, content, lines = future.result()
                processed += 1
                
                if success and content:
                    contents[url] = content
                    print(f"  [{processed}/{total}] âœ… è·å–æˆåŠŸ: {url} ({lines} è¡Œ)")
                    self.stats['rules_by_source'][url] = lines
                else:
                    print(f"  [{processed}/{total}] âŒ è·å–å¤±è´¥: {url}")
        
        print(f"\nğŸ” åˆ†æè§„åˆ™å†…å®¹...")
        previous_counts = {
            'adblock': len(self.adblock_rules),
            'hosts': len(self.hosts_entries),
            'domains': len(self.domains_set)
        }
        
        for url, content in contents.items():
            self._parse_content(content, url)
        
        print(f"\nğŸ§¹ å¼€å§‹æ™ºèƒ½å»é‡å’Œä¼˜åŒ–...")
        
        # è®°å½•å»é‡å‰çš„æ•°é‡
        before_dedup = {
            'adblock': len(self.adblock_rules),
            'hosts': len(self.hosts_entries),
            'domains': len(self.domains_set)
        }
        
        # åº”ç”¨æ™ºèƒ½å»é‡
        self.adblock_rules = self.optimizer.deduplicate_adblock_rules(self.adblock_rules)
        self.hosts_entries = self.optimizer.deduplicate_hosts_entries(self.hosts_entries)
        self.domains_set = self.optimizer.deduplicate_domains(self.domains_set)
        
        # è®°å½•å»é‡æ•ˆæœ
        self.stats['duplicates_removed'] = {
            'adblock': before_dedup['adblock'] - len(self.adblock_rules),
            'hosts': before_dedup['hosts'] - len(self.hosts_entries),
            'domains': before_dedup['domains'] - len(self.domains_set)
        }
        
        self.stats['rules_processed'] = len(self.adblock_rules) + len(self.hosts_entries) + len(self.domains_set)
        
        current_counts = {
            'adblock': len(self.adblock_rules),
            'hosts': len(self.hosts_entries),
            'domains': len(self.domains_set)
        }
        
        if all(count > 0 for count in current_counts.values()):
            if any(current_counts[k] != previous_counts[k] for k in current_counts):
                self.stats['update_status'] = 'updated'
            else:
                self.stats['update_status'] = 'no_change'
        else:
            self.stats['update_status'] = 'failed'
        
        print(f"\nğŸ’¾ ä¿å­˜ä¼˜åŒ–åçš„è§„åˆ™æ–‡ä»¶...")
        success = self._save_results()
        
        elapsed_time = time.time() - start_timestamp
        self.stats['end_time'] = get_time_string()
        self.stats['total_duration'] = round(elapsed_time, 2)
        
        self._generate_detailed_stats()
        
        print("=" * 60)
        if success:
            status_emoji = "ğŸ”„" if self.stats['update_status'] == 'updated' else "â¸ï¸"
            print(f"{status_emoji} å¤„ç†å®Œæˆï¼çŠ¶æ€: {self.stats['update_status']}")
            print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
            print(f"ğŸ“Š Adblockè§„åˆ™: {current_counts['adblock']} æ¡")
            print(f"ğŸ“Š Hostsè§„åˆ™: {current_counts['hosts']} ä¸ª")
            print(f"ğŸ“Š çº¯åŸŸå: {current_counts['domains']} ä¸ª")
            print(f"ğŸ“ˆ å»é‡ç»Ÿè®¡: {self.stats['duplicates_removed']['adblock']}æ¡Adblock, "
                  f"{self.stats['duplicates_removed']['hosts']}ä¸ªHosts, "
                  f"{self.stats['duplicates_removed']['domains']}ä¸ªåŸŸå")
            print(f"ğŸ“ˆ è§„åˆ™æº: {self.fetcher.stats['successful']}æˆåŠŸ/{self.fetcher.stats['failed']}å¤±è´¥")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥")
        
        print("=" * 60)
        return success and self.stats['update_status'] != 'failed'
    
    def _parse_content(self, content: str, source_url: str):
        """è§£æè§„åˆ™å†…å®¹ï¼Œåˆ†ç¦»ä¸‰ç§æ ¼å¼"""
        lines = content.split('\n')
        counts = {'adblock': 0, 'hosts': 0, 'domains': 0}
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('!') or line.startswith('#'):
                continue
            
            # 1. è¯†åˆ«Adblock-styleè§„åˆ™
            if (line.startswith('||') and line.endswith('^')) or \
               line.startswith('|') or \
               '##' in line or \
               (line.startswith('/') and line.endswith('/')):
                self.adblock_rules.add(line)
                counts['adblock'] += 1
            
            # 2. è¯†åˆ«Hostsè§„åˆ™
            elif re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\s+', line):
                parts = line.split()
                if len(parts) >= 2 and parts[0] in ['0.0.0.0', '127.0.0.1']:
                    rule = f"{parts[0]} {parts[1]}"
                    self.hosts_entries.add(rule)
                    counts['hosts'] += 1
                    
                    domain = parts[1]
                    if self._is_valid_domain(domain):
                        self.domains_set.add(domain)
                        counts['domains'] += 1
            
            # 3. è¯†åˆ«çº¯åŸŸå
            elif self._is_valid_domain(line):
                self.domains_set.add(line)
                counts['domains'] += 1
        
        if any(counts.values()):
            self.stats['rules_by_source'][source_url] = counts
    
    def _is_valid_domain(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åŸŸåæ ¼å¼"""
        if not text or ' ' in text or '#' in text or '!' in text:
            return False
        domain_pattern = r'^([a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}$'
        return bool(re.match(domain_pattern, text))
    
    def _save_results(self) -> bool:
        """ä¿å­˜ä¸‰ç§æ ¼å¼çš„è§„åˆ™ç»“æœ"""
        try:
            os.makedirs("dist", exist_ok=True)
            os.makedirs("stats", exist_ok=True)
            
            current_time = get_time_string()
            
            # 1. ä¿å­˜Adblockè§„åˆ™
            adblock_path = "dist/Adblock.txt"
            with open(adblock_path, 'w', encoding='utf-8') as f:
                f.write(f"""! Adblock-style è§„åˆ™ï¼ˆæ™ºèƒ½å»é‡ä¼˜åŒ–ç‰ˆï¼‰
! é€‚ç”¨äº uBlock Origin, AdGuard, Adblock Plus ç­‰æµè§ˆå™¨æ’ä»¶
! æœ€åæ›´æ–°: {current_time}
! è§„åˆ™æ€»æ•°: {len(self.adblock_rules)} æ¡
! å»é‡ç§»é™¤: {self.stats['duplicates_removed']['adblock']} æ¡é‡å¤è§„åˆ™
! æ›´æ–°çŠ¶æ€: {self.stats['update_status']}
! GitHub: https://github.com/wansheng8/ad-rule-automation
!

""")
                for rule in sorted(self.adblock_rules):
                    f.write(f"{rule}\n")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(adblock_path)
            file_size_mb = file_size / (1024 * 1024)
            print(f"  âœ… ä¿å­˜Adblockè§„åˆ™: {len(self.adblock_rules)} æ¡ -> dist/Adblock.txt ({file_size_mb:.2f} MB)")
            
            if file_size_mb > 90:
                print(f"  âš ï¸  è­¦å‘Š: Adblock.txt æ–‡ä»¶è¾ƒå¤§ ({file_size_mb:.2f} MB)")
                print(f"  ğŸ’¡ å»ºè®®: å¦‚éœ€è¿›ä¸€æ­¥å‡å°æ–‡ä»¶å¤§å°ï¼Œå¯è€ƒè™‘:")
                print(f"     1. å‡å°‘è§„åˆ™æºæ•°é‡")
                print(f"     2. å¯ç”¨è§„åˆ™å‹ç¼©ï¼ˆå¯è”ç³»å¼€å‘è€…å¯ç”¨ï¼‰")
            
            # 2. ä¿å­˜Hostsè§„åˆ™
            hosts_path = "dist/hosts.txt"
            with open(hosts_path, 'w', encoding='utf-8') as f:
                f.write(f"""# /etc/hosts è¯­æ³•è§„åˆ™ï¼ˆæ™ºèƒ½å»é‡ä¼˜åŒ–ç‰ˆï¼‰
# é€‚ç”¨äºç³»ç»Ÿhostsæ–‡ä»¶ã€Pi-holeã€AdGuard Homeç­‰
# æœ€åæ›´æ–°: {current_time}
# è§„åˆ™æ€»æ•°: {len(self.hosts_entries)} ä¸ª
# å»é‡ç§»é™¤: {self.stats['duplicates_removed']['hosts']} ä¸ªé‡å¤åŸŸå
# æ›´æ–°çŠ¶æ€: {self.stats['update_status']}
# GitHub: https://github.com/wansheng8/ad-rule-automation
#

""")
                sorted_hosts = sorted(self.hosts_entries)
                zero_hosts = [h for h in sorted_hosts if h.startswith('0.0.0.0')]
                local_hosts = [h for h in sorted_hosts if h.startswith('127.0.0.1')]
                for rule in zero_hosts + local_hosts:
                    f.write(f"{rule}\n")
            
            print(f"  âœ… ä¿å­˜Hostsè§„åˆ™: {len(self.hosts_entries)} ä¸ª -> dist/hosts.txt")
            
            # 3. ä¿å­˜çº¯åŸŸååˆ—è¡¨
            domains_path = "dist/Domains.txt"
            with open(domains_path, 'w', encoding='utf-8') as f:
                f.write(f"""# çº¯åŸŸååˆ—è¡¨ï¼ˆæ™ºèƒ½å»é‡ä¼˜åŒ–ç‰ˆï¼‰
# é€‚ç”¨äºDNSè¿‡æ»¤ã€é˜²ç«å¢™è§„åˆ™ç­‰
# æœ€åæ›´æ–°: {current_time}
# åŸŸåæ€»æ•°: {len(self.domains_set)} ä¸ª
# å»é‡ç§»é™¤: {self.stats['duplicates_removed']['domains']} ä¸ªé‡å¤åŸŸå
# æ›´æ–°çŠ¶æ€: {self.stats['update_status']}
# GitHub: https://github.com/wansheng8/ad-rule-automation
#

""")
                for domain in sorted(self.domains_set):
                    f.write(f"{domain}\n")
            
            print(f"  âœ… ä¿å­˜çº¯åŸŸååˆ—è¡¨: {len(self.domains_set)} ä¸ª -> dist/Domains.txt")
            
            return True
            
        except Exception as e:
            print(f"  âŒ ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _generate_detailed_stats(self):
        """ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š"""
        try:
            timestamp = get_shanghai_time().strftime('%Y%m%d_%H%M%S')
            stats_file = f"stats/processing_stats_{timestamp}.json"
            
            detailed_stats = {
                "processing_info": {
                    "start_time": self.stats['start_time'],
                    "end_time": self.stats['end_time'],
                    "total_duration_seconds": self.stats['total_duration'],
                    "update_status": self.stats['update_status'],
                    "shanghai_timezone": True
                },
                "rules_summary": {
                    "adblock_rules": len(self.adblock_rules),
                    "hosts_entries": len(self.hosts_entries),
                    "domains": len(self.domains_set),
                    "total_processed": self.stats['rules_processed']
                },
                "duplicates_removed": self.stats['duplicates_removed'],
                "sources_summary": self.fetcher.stats,
                "rules_by_source": self.stats['rules_by_source'],
                "output_files": {
                    "adblock": "dist/Adblock.txt",
                    "hosts": "dist/hosts.txt",
                    "domains": "dist/Domains.txt"
                }
            }
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_stats, f, indent=2, ensure_ascii=False)
            
            print(f"  ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {stats_file}")
            
            # ç”ŸæˆMarkdownæŠ¥å‘Š
            self._generate_markdown_report(detailed_stats, timestamp)
            
        except Exception as e:
            print(f"  âš ï¸  ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    def _generate_markdown_report(self, stats_data, timestamp):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        try:
            md_file = f"stats/report_{timestamp}.md"
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(f"# å¹¿å‘Šè§„åˆ™å¤„ç†æŠ¥å‘Šï¼ˆæ™ºèƒ½å»é‡ç‰ˆï¼‰\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {stats_data['processing_info']['end_time']}\n")
                f.write(f"**çŠ¶æ€**: {stats_data['processing_info']['update_status']}\n")
                f.write(f"**è¾“å‡ºæ–‡ä»¶**: [Adblock.txt](dist/Adblock.txt), [hosts.txt](dist/hosts.txt), [Domains.txt](dist/Domains.txt)\n\n")
                
                f.write(f"## å¤„ç†æ¦‚è§ˆ\n\n")
                f.write(f"- **æ€»è€—æ—¶**: {stats_data['processing_info']['total_duration_seconds']}ç§’\n")
                f.write(f"- **è§„åˆ™æº**: {stats_data['sources_summary']['successful']}æˆåŠŸ/{stats_data['sources_summary']['failed']}å¤±è´¥\n\n")
                
                f.write(f"## è§„åˆ™ç»Ÿè®¡ï¼ˆå»é‡åï¼‰\n\n")
                f.write(f"- **Adblockè§„åˆ™**: {stats_data['rules_summary']['adblock_rules']}æ¡\n")
                f.write(f"- **Hostsè§„åˆ™**: {stats_data['rules_summary']['hosts_entries']}ä¸ª\n")
                f.write(f"- **çº¯åŸŸå**: {stats_data['rules_summary']['domains']}ä¸ª\n")
                f.write(f"- **æ€»è®¡**: {stats_data['rules_summary']['total_processed']}æ¡è§„åˆ™\n\n")
                
                f.write(f"## å»é‡æ•ˆæœ\n\n")
                f.write(f"- **ç§»é™¤çš„Adblocké‡å¤è§„åˆ™**: {stats_data['duplicates_removed']['adblock']}æ¡\n")
                f.write(f"- **ç§»é™¤çš„Hostsé‡å¤åŸŸå**: {stats_data['duplicates_removed']['hosts']}ä¸ª\n")
                f.write(f"- **ç§»é™¤çš„åŸŸåé‡å¤**: {stats_data['duplicates_removed']['domains']}ä¸ª\n")
            
            print(f"  ğŸ“‹ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")
        except Exception as e:
            print(f"  âš ï¸  ç”ŸæˆMarkdownæŠ¥å‘Šæ—¶å‡ºé”™: {e}")

def verify_configuration():
    """éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½"""
    try:
        print("ğŸ”§ éªŒè¯é…ç½®...")
        all_sources = get_all_sources()
        
        if not all_sources:
            print("âŒ é…ç½®æ–‡ä»¶é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è§„åˆ™æºURL")
            print("ğŸ’¡ è¯·æ£€æŸ¥ config/rule_sources.txt æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªURLï¼‰")
            return False
        
        print(f"âœ… é…ç½®éªŒè¯é€šè¿‡: ä»TXTæ–‡ä»¶åŠ è½½äº† {len(all_sources)} ä¸ªè§„åˆ™æº")
        
        print("ğŸ“‹ è§„åˆ™æºç¤ºä¾‹:")
        for i, url in enumerate(all_sources[:3], 1):
            from urllib.parse import urlparse
            domain = urlparse(url).netloc
            print(f"  {i}. [{domain}]")
        if len(all_sources) > 3:
            print(f"  ... è¿˜æœ‰ {len(all_sources) - 3} ä¸ªè§„åˆ™æº")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– æ™ºèƒ½å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ (æ™ºèƒ½å»é‡ç‰ˆ)")
    print("=" * 60)
    
    if not verify_configuration():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¿è¡Œ")
        return 1
    
    processor = RuleProcessor()
    
    try:
        success = processor.process_rules()
        return 0 if success else 1
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        return 130
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
