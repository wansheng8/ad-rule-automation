#!/usr/bin/env python3
"""
å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ - è¶…å¼ºä¼˜åŒ–ç‰ˆ
ä¸“ä¸ºGitHub Actionsç¯å¢ƒä¼˜åŒ–ï¼Œè§£å†³è¶…æ—¶é—®é¢˜
"""

import os
import sys
import re
import time
import json
import signal
import pickle
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Set, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.settings import get_all_sources, Config
except ImportError as e:
    print(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")
    sys.exit(1)

# ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
DOMAIN_PATTERN = re.compile(r'^([a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}$')
HOSTS_PATTERN = re.compile(r'^(0\.0\.0\.0|127\.0\.0\.1)\s+(\S+)')
ADBLOCK_PATTERN = re.compile(r'^\|\|([a-zA-Z0-9.*-]+)\^')

# === å…¨å±€è¶…æ—¶æ§åˆ¶ ===
class TimeoutException(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutException("å¤„ç†è¶…æ—¶ï¼Œå·²å¼ºåˆ¶åœæ­¢")

signal.signal(signal.SIGALRM, timeout_handler)

def get_shanghai_time() -> datetime:
    """è·å–å½“å‰ä¸Šæµ·æ—¶é—´"""
    try:
        shanghai_tz = timezone(timedelta(hours=8))
        return datetime.now(shanghai_tz)
    except:
        return datetime.now()

def get_time_string() -> str:
    return get_shanghai_time().strftime('%Y-%m-%d %H:%M:%S')

class UltraFastRuleFetcher:
    """æé€Ÿè§„åˆ™è·å–å™¨"""
    
    def __init__(self):
        try:
            import requests
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            self.requests = requests
            self.HTTPAdapter = HTTPAdapter
            self.Retry = Retry
        except ImportError as e:
            print(f"âŒ å¯¼å…¥requestså¤±è´¥: {e}")
            print("ğŸ’¡ è¯·è¿è¡Œ: pip install requests")
            sys.exit(1)
            
        self.session = self._create_session()
        self.stats = {
            'total': 0,
            'success': 0,
            'cached': 0,
            'failed': 0,
            'timeout': 0
        }
        self.cache_dir = Path(Config.CACHE_DIR)
        self.cache_dir.mkdir(exist_ok=True)
        
    def _create_session(self):
        """åˆ›å»ºè¶…å¿«é€Ÿä¼šè¯"""
        session = self.requests.Session()
        retry = self.Retry(total=1, backoff_factor=0.5)
        adapter = self.HTTPAdapter(
            max_retries=retry,
            pool_connections=5,
            pool_maxsize=5
        )
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        session.headers.update({
            'User-Agent': Config.get_user_agent(),
            'Accept': 'text/plain',
            'Accept-Encoding': 'gzip',
            'Connection': 'close'
        })
        
        return session
    
    def _get_cache_key(self, url: str) -> Path:
        return self.cache_dir / f"cache_{hashlib.md5(url.encode()).hexdigest()}.txt"
    
    def fetch_with_cache(self, url: str) -> Tuple[bool, Optional[str], int]:
        """å¸¦ç¼“å­˜çš„è·å–ï¼ˆæé€Ÿç‰ˆï¼‰"""
        cache_file = self._get_cache_key(url)
        
        # æ£€æŸ¥ç¼“å­˜
        if Config.CACHE_ENABLED and cache_file.exists():
            cache_age = time.time() - cache_file.stat().st_mtime
            if cache_age < Config.CACHE_EXPIRE_HOURS * 3600:
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = content.count('\n')
                        self.stats['cached'] += 1
                        self.stats['success'] += 1
                        return True, content, lines
                except:
                    pass
        
        # ç½‘ç»œè·å–ï¼ˆå¸¦ä¸¥æ ¼è¶…æ—¶ï¼‰
        try:
            signal.alarm(Config.REQUEST_TIMEOUT + 5)  # è®¾ç½®ç³»ç»Ÿçº§è¶…æ—¶
            response = self.session.get(
                url, 
                timeout=Config.REQUEST_TIMEOUT,
                stream=False  # ç¦ç”¨æµå¼ï¼ŒåŠ å¿«å°æ–‡ä»¶
            )
            signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
            
            response.raise_for_status()
            content = response.text
            lines = content.count('\n') + 1
            
            # ä¿å­˜ç¼“å­˜
            if Config.CACHE_ENABLED:
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                except:
                    pass
            
            self.stats['success'] += 1
            return True, content, lines
            
        except TimeoutError:
            self.stats['timeout'] += 1
            return False, None, 0
        except Exception as e:
            self.stats['failed'] += 1
            return False, None, 0
        finally:
            signal.alarm(0)

class FastRuleOptimizer:
    """æé€Ÿè§„åˆ™ä¼˜åŒ–å™¨"""
    
    @staticmethod
    def simple_deduplicate(rules: List[str]) -> List[str]:
        """æç®€å»é‡ï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰"""
        if not rules:
            return []
        
        # ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿå»é‡
        seen = set()
        unique_rules = []
        
        for rule in rules:
            if rule not in seen:
                seen.add(rule)
                unique_rules.append(rule)
        
        # ç¬¬äºŒæ­¥ï¼šç®€å•åŸŸåå»é‡ï¼ˆä»…å¯¹Adblockè§„åˆ™ï¼‰
        if len(unique_rules) > 10000:  # åªæœ‰è§„åˆ™å¤šæ—¶æ‰å¯ç”¨
            domain_map = {}
            final_rules = []
            
            for rule in unique_rules:
                # å¿«é€Ÿæå–åŸŸå
                domain = None
                if rule.startswith('||') and '^' in rule:
                    domain = rule[2:].split('^')[0]
                elif rule.startswith('0.0.0.0 ') or rule.startswith('127.0.0.1 '):
                    parts = rule.split()
                    if len(parts) >= 2:
                        domain = parts[1]
                
                if domain:
                    if domain not in domain_map:
                        domain_map[domain] = rule
                        final_rules.append(rule)
                else:
                    final_rules.append(rule)
            
            return final_rules
        
        return unique_rules
    
    @staticmethod
    def filter_and_sort_rules(rules: List[str]) -> List[str]:
        """è¿‡æ»¤å’Œæ’åºè§„åˆ™"""
        if not rules:
            return []
        
        # æŒ‰è§„åˆ™ç±»å‹åˆ†ç»„
        adblock_rules = []
        hosts_rules = []
        domain_rules = []
        
        for rule in rules:
            rule_lower = rule.lower()
            
            # è·³è¿‡æ˜æ˜¾æ— æ•ˆçš„è§„åˆ™
            if len(rule) > 500:  # è¿‡é•¿çš„è§„åˆ™
                continue
            if ' ' in rule and not rule.startswith(('0.0.0.0', '127.0.0.1')):
                continue
            
            # åˆ†ç±»
            if rule.startswith('||') or '##' in rule or rule.startswith('|'):
                adblock_rules.append(rule)
            elif rule.startswith('0.0.0.0') or rule.startswith('127.0.0.1'):
                hosts_rules.append(rule)
            elif DOMAIN_PATTERN.match(rule):
                domain_rules.append(rule)
        
        # åˆå¹¶å¹¶é™åˆ¶æ•°é‡
        all_rules = []
        all_rules.extend(sorted(adblock_rules)[:Config.MAX_RULES_PER_TYPE])
        all_rules.extend(sorted(hosts_rules)[:Config.MAX_RULES_PER_TYPE//2])
        all_rules.extend(sorted(domain_rules)[:Config.MAX_RULES_PER_TYPE//2])
        
        return all_rules[:Config.MAX_TOTAL_RULES]

class SmartRuleProcessor:
    """æ™ºèƒ½è§„åˆ™å¤„ç†å™¨ï¼ˆè§£å†³è¶…æ—¶é—®é¢˜ï¼‰"""
    
    def __init__(self):
        self.fetcher = UltraFastRuleFetcher()
        self.optimizer = FastRuleOptimizer()
        self.all_rules = []
        
        # åŠ è½½è§„åˆ™æºï¼ˆè‡ªåŠ¨è¿‡æ»¤ï¼‰
        try:
            sources = get_all_sources()
            self.rule_sources = sources[:80] if len(sources) > 80 else sources  # æœ€å¤š80ä¸ª
        except:
            self.rule_sources = [
                "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt",
                "https://easylist.to/easylist/easylist.txt",
                "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",
            ]
        
        self.start_time = time.time()
        self.stats = {
            'total_sources': len(self.rule_sources),
            'processed_sources': 0,
            'total_rules': 0,
            'final_rules': 0,
            'duration': 0,
            'status': 'unknown'
        }
    
    def check_timeout(self):
        """æ£€æŸ¥æ˜¯å¦è¶…æ—¶"""
        elapsed = time.time() - self.start_time
        if elapsed > Config.TIMEOUT_FORCE_STOP:
            print(f"â° è¶…æ—¶ä¿æŠ¤è§¦å‘ï¼šå·²è¿è¡Œ {elapsed:.0f} ç§’ï¼Œå¼ºåˆ¶åœæ­¢")
            return True
        return False
    
    def process(self) -> bool:
        """ä¸»å¤„ç†æµç¨‹"""
        print("=" * 70)
        print("ğŸš€ å¹¿å‘Šè§„åˆ™å¤„ç†ç³»ç»Ÿ - è¶…å¼ºä¼˜åŒ–ç‰ˆ")
        print(f"ğŸ“… å¼€å§‹æ—¶é—´: {get_time_string()}")
        print(f"ğŸ“Š è§„åˆ™æº: {self.stats['total_sources']} ä¸ª")
        print(f"âš™ï¸  é…ç½®: å¹¶å‘={Config.MAX_WORKERS}, è¶…æ—¶={Config.REQUEST_TIMEOUT}s")
        print("=" * 70)
        
        # è®¾ç½®æ€»è¶…æ—¶
        signal.alarm(Config.TIMEOUT_FORCE_STOP + 60)
        
        try:
            # é˜¶æ®µ1ï¼šå¹¶è¡Œä¸‹è½½ï¼ˆä¸¥æ ¼æ§åˆ¶ï¼‰
            print(f"\nğŸ“¥ é˜¶æ®µ1: ä¸‹è½½è§„åˆ™æº")
            contents = self._fetch_all_sources()
            
            if self.check_timeout():
                return False
            
            # é˜¶æ®µ2ï¼šå¿«é€Ÿè§£æ
            print(f"\nğŸ” é˜¶æ®µ2: è§£æè§„åˆ™")
            self._parse_contents(contents)
            
            if self.check_timeout():
                return False
            
            # é˜¶æ®µ3ï¼šæé€Ÿä¼˜åŒ–
            print(f"\nâš¡ é˜¶æ®µ3: ä¼˜åŒ–è§„åˆ™")
            final_rules = self._optimize_rules()
            
            if self.check_timeout():
                return False
            
            # é˜¶æ®µ4ï¼šä¿å­˜ç»“æœ
            print(f"\nğŸ’¾ é˜¶æ®µ4: ä¿å­˜ç»“æœ")
            success = self._save_results(final_rules)
            
            # ç”ŸæˆæŠ¥å‘Š
            self._generate_report(success)
            
            signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
            return success
            
        except TimeoutException:
            print("\nâ° å¤„ç†è¶…æ—¶ï¼Œä¿å­˜å·²å¤„ç†çš„æ•°æ®...")
            self._save_partial_results()
            self.stats['status'] = 'timeout'
            return False
        except Exception as e:
            print(f"\nâŒ å¤„ç†å¼‚å¸¸: {e}")
            self.stats['status'] = 'error'
            return False
    
    def _fetch_all_sources(self) -> Dict[str, str]:
        """å¹¶è¡Œè·å–æ‰€æœ‰æº"""
        contents = {}
        max_workers = min(Config.MAX_WORKERS, 4)  # æœ€å¤§4ä¸ªå¹¶å‘
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(self.fetcher.fetch_with_cache, url): url 
                      for url in self.rule_sources}
            
            completed = 0
            batch_size = 10
            
            for future in as_completed(futures):
                url = futures[future]
                success, content, lines = future.result()
                
                completed += 1
                
                if success and content:
                    contents[url] = content
                    status = "ç¼“å­˜" if self.fetcher.stats['cached'] > 0 and \
                        completed <= self.fetcher.stats['cached'] else "ä¸‹è½½"
                    
                    if completed % batch_size == 0 or completed == len(self.rule_sources):
                        print(f"  [{completed}/{len(self.rule_sources)}] {status} {lines:6d} è¡Œ")
                else:
                    if completed % batch_size == 0 or completed == len(self.rule_sources):
                        print(f"  [{completed}/{len(self.rule_sources)}] å¤±è´¥")
                
                # å®šæœŸæ£€æŸ¥è¶…æ—¶
                if completed % 20 == 0 and self.check_timeout():
                    break
        
        print(f"âœ… ä¸‹è½½å®Œæˆ: {len(contents)}æˆåŠŸ, {self.fetcher.stats['failed']}å¤±è´¥, "
              f"{self.fetcher.stats['cached']}ç¼“å­˜")
        return contents
    
    def _parse_contents(self, contents: Dict[str, str]):
        """è§£ææ‰€æœ‰å†…å®¹"""
        rule_count = 0
        batch_size = 50000
        
        for url, content in contents.items():
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if not line or line[0] in '!#':
                    continue
                
                # å¿«é€Ÿåˆ†ç±»
                if len(line) < 500:  # è·³è¿‡è¿‡é•¿çš„è¡Œ
                    self.all_rules.append(line)
                    rule_count += 1
                
                # å®šæœŸæ£€æŸ¥è¶…æ—¶å’Œæ•°é‡é™åˆ¶
                if rule_count % batch_size == 0:
                    print(f"  å·²è§£æ {rule_count:,} æ¡è§„åˆ™")
                    if self.check_timeout():
                        return
                    if rule_count > Config.MAX_TOTAL_RULES * 2:
                        print(f"âš ï¸  è§„åˆ™æ•°é‡è¿‡å¤šï¼Œæå‰åœæ­¢è§£æ")
                        return
        
        self.stats['total_rules'] = rule_count
        print(f"âœ… è§£æå®Œæˆ: {rule_count:,} æ¡åŸå§‹è§„åˆ™")
    
    def _optimize_rules(self) -> List[str]:
        """ä¼˜åŒ–è§„åˆ™"""
        print(f"  å¼€å§‹ä¼˜åŒ– {len(self.all_rules):,} æ¡è§„åˆ™...")
        
        # ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿå»é‡
        unique_start = time.time()
        unique_rules = self.optimizer.simple_deduplicate(self.all_rules)
        unique_time = time.time() - unique_start
        print(f"  å»é‡å®Œæˆ: {len(unique_rules):,} æ¡ (è€—æ—¶: {unique_time:.1f}s)")
        
        if self.check_timeout():
            return unique_rules[:10000]  # è¿”å›éƒ¨åˆ†ç»“æœ
        
        # ç¬¬äºŒæ­¥ï¼šè¿‡æ»¤å’Œæ’åº
        filter_start = time.time()
        final_rules = self.optimizer.filter_and_sort_rules(unique_rules)
        filter_time = time.time() - filter_start
        
        self.stats['final_rules'] = len(final_rules)
        print(f"  è¿‡æ»¤å®Œæˆ: {len(final_rules):,} æ¡ (è€—æ—¶: {filter_time:.1f}s)")
        
        return final_rules
    
    def _save_results(self, rules: List[str]) -> bool:
        """ä¿å­˜ç»“æœ"""
        try:
            os.makedirs("dist", exist_ok=True)
            os.makedirs("stats", exist_ok=True)
            
            current_time = get_time_string()
            total_rules = len(rules)
            
            # æ™ºèƒ½åˆ†å‰²è§„åˆ™
            adblock_rules = []
            hosts_rules = []
            domain_rules = []
            
            for rule in rules:
                if rule.startswith('||') or '##' in rule or rule.startswith('|'):
                    adblock_rules.append(rule)
                elif rule.startswith('0.0.0.0') or rule.startswith('127.0.0.1'):
                    hosts_rules.append(rule)
                else:
                    domain_rules.append(rule)
            
            # ä¿å­˜Adblockè§„åˆ™
            if adblock_rules:
                with open("dist/Adblock.txt", 'w', encoding='utf-8') as f:
                    f.write(f"""! Adblockè§„åˆ™ - è¶…å¼ºä¼˜åŒ–ç‰ˆ
! ç”Ÿæˆæ—¶é—´: {current_time}
! è§„åˆ™æ•°é‡: {len(adblock_rules):,}
! é¡¹ç›®åœ°å€: https://github.com/{Config.REPO_OWNER}/{Config.REPO_NAME}
!

""")
                    # æ‰¹é‡å†™å…¥
                    for i in range(0, len(adblock_rules), 10000):
                        batch = adblock_rules[i:i+10000]
                        f.write('\n'.join(batch) + '\n')
                
                print(f"  âœ… Adblockè§„åˆ™: {len(adblock_rules):,} æ¡")
            
            # ä¿å­˜Hostsè§„åˆ™
            if hosts_rules:
                with open("dist/hosts.txt", 'w', encoding='utf-8') as f:
                    f.write(f"""# Hostsè§„åˆ™ - è¶…å¼ºä¼˜åŒ–ç‰ˆ
# ç”Ÿæˆæ—¶é—´: {current_time}
# è§„åˆ™æ•°é‡: {len(hosts_rules):,}
# é¡¹ç›®åœ°å€: https://github.com/{Config.REPO_OWNER}/{Config.REPO_NAME}
#

""")
                    for i in range(0, len(hosts_rules), 10000):
                        batch = hosts_rules[i:i+10000]
                        f.write('\n'.join(batch) + '\n')
                
                print(f"  âœ… Hostsè§„åˆ™: {len(hosts_rules):,} æ¡")
            
            # ä¿å­˜åŸŸåè§„åˆ™
            if domain_rules:
                with open("dist/Domains.txt", 'w', encoding='utf-8') as f:
                    f.write(f"""# åŸŸåè§„åˆ™ - è¶…å¼ºä¼˜åŒ–ç‰ˆ
# ç”Ÿæˆæ—¶é—´: {current_time}
# åŸŸåæ•°é‡: {len(domain_rules):,}
# é¡¹ç›®åœ°å€: https://github.com/{Config.REPO_OWNER}/{Config.REPO_NAME}
#

""")
                    for i in range(0, len(domain_rules), 10000):
                        batch = domain_rules[i:i+10000]
                        f.write('\n'.join(batch) + '\n')
                
                print(f"  âœ… åŸŸåè§„åˆ™: {len(domain_rules):,} æ¡")
            
            print(f"  ğŸ’¾ æ€»è®¡ä¿å­˜: {total_rules:,} æ¡è§„åˆ™")
            return True
            
        except Exception as e:
            print(f"  âŒ ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def _save_partial_results(self):
        """ä¿å­˜éƒ¨åˆ†ç»“æœï¼ˆè¶…æ—¶æƒ…å†µä¸‹ï¼‰"""
        try:
            if self.all_rules:
                # åªä¿å­˜å‰5ä¸‡æ¡è§„åˆ™
                sample_rules = self.all_rules[:50000]
                optimized = self.optimizer.simple_deduplicate(sample_rules)
                
                os.makedirs("dist", exist_ok=True)
                with open("dist/Adblock_partial.txt", 'w', encoding='utf-8') as f:
                    f.write(f"! éƒ¨åˆ†è§„åˆ™ (è¶…æ—¶ä¿æŠ¤è§¦å‘)\n")
                    f.write(f"! ç”Ÿæˆæ—¶é—´: {get_time_string()}\n")
                    f.write(f"! è§„åˆ™æ•°é‡: {len(optimized):,}\n!\n\n")
                    f.write('\n'.join(optimized[:20000]))
                
                print(f"  âš ï¸  å·²ä¿å­˜éƒ¨åˆ†è§„åˆ™ ({len(optimized):,} æ¡)")
        except:
            pass
    
    def _generate_report(self, success: bool):
        """ç”ŸæˆæŠ¥å‘Š"""
        try:
            elapsed = time.time() - self.start_time
            self.stats['duration'] = round(elapsed, 2)
            self.stats['status'] = 'success' if success else 'partial'
            
            report = {
                'timestamp': get_time_string(),
                'stats': self.stats,
                'fetcher_stats': self.fetcher.stats,
                'config': {
                    'max_workers': Config.MAX_WORKERS,
                    'timeout': Config.REQUEST_TIMEOUT,
                    'cache_enabled': Config.CACHE_ENABLED,
                    'max_rules': Config.MAX_TOTAL_RULES
                }
            }
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            with open(f"stats/report_{timestamp}.json", 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # ç®€ç‰ˆæ§åˆ¶å°æŠ¥å‘Š
            print(f"\n{'='*70}")
            print(f"{'âœ… å¤„ç†æˆåŠŸ' if success else 'âš ï¸  éƒ¨åˆ†å®Œæˆ'}")
            print(f"{'='*70}")
            print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.1f} ç§’")
            print(f"ğŸ“Š åŸå§‹è§„åˆ™: {self.stats['total_rules']:,} æ¡")
            print(f"ğŸ“Š æœ€ç»ˆè§„åˆ™: {self.stats['final_rules']:,} æ¡")
            print(f"ğŸ“¥ ä¸‹è½½ç»Ÿè®¡: {self.fetcher.stats['success']}æˆåŠŸ "
                  f"({self.fetcher.stats['cached']}ç¼“å­˜) / "
                  f"{self.fetcher.stats['failed']}å¤±è´¥ / "
                  f"{self.fetcher.stats['timeout']}è¶…æ—¶")
            
        except Exception as e:
            print(f"  âš ï¸  æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ å¯åŠ¨å¹¿å‘Šè§„åˆ™å¤„ç†ç³»ç»Ÿ")
    
    # è®¾ç½®Ctrl+Cå¤„ç†
    def interrupt_handler(sig, frame):
        print("\n\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜å½“å‰è¿›åº¦...")
        sys.exit(130)
    
    signal.signal(signal.SIGINT, interrupt_handler)
    
    try:
        processor = SmartRuleProcessor()
        success = processor.process()
        
        return 0 if success else 1
        
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        signal.alarm(0)  # ç¡®ä¿å–æ¶ˆæ‰€æœ‰è¶…æ—¶

if __name__ == "__main__":
    sys.exit(main())
