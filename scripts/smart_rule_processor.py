#!/usr/bin/env python3
"""
å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ - å¤šé˜¶æ®µä¼˜åŒ–ç‰ˆ
åŒ…å«ï¼šä¸‹è½½ â†’ è§£æ â†’ å»é‡ â†’ ä¼˜åŒ– â†’ äºŒæ¬¡ä¼˜åŒ– â†’ è¾“å‡º
"""

import os
import sys
import re
import time
import json
import signal
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Set, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.settings import get_all_sources, Config
except ImportError as e:
    print(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")
    sys.exit(1)

# ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
DOMAIN_PATTERN = re.compile(r'^([a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}$')
HOSTS_PATTERN = re.compile(r'^(0\.0\.0\.0|127\.0\.0\.1)\s+(\S+)')
ADBLOCK_DOMAIN_PATTERN = re.compile(r'^\|\|([a-zA-Z0-9.*-]+)\^')
ADBLOCK_ELEMENT_PATTERN = re.compile(r'^([^#]+)##(.+)$')

# è¶…æ—¶æ§åˆ¶
class TimeoutException(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutException("å¤„ç†è¶…æ—¶")

signal.signal(signal.SIGALRM, timeout_handler)

def get_shanghai_time() -> datetime:
    """è·å–å½“å‰ä¸Šæµ·æ—¶é—´"""
    try:
        shanghai_tz = timezone(timedelta(hours=8))
        return datetime.now(shanghai_tz)
    except:
        return datetime.now()

def get_time_string() -> str:
    return get_shanghai_time().strftime('%Y-%m-%d %H:%M:%S')

class AdvancedRuleFetcher:
    """é«˜çº§è§„åˆ™è·å–å™¨"""
    
    def __init__(self):
        try:
            import requests
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            self.requests = requests
            self.HTTPAdapter = HTTPAdapter
            self.Retry = Retry
        except ImportError as e:
            print(f"âŒ å¯¼å…¥requestså¤±è´¥: {e}")
            sys.exit(1)
        
        self.session = self._create_session()
        self.cache_dir = Path(Config.CACHE_DIR)
        self.cache_dir.mkdir(exist_ok=True)
        
        self.stats = {
            'total': 0, 'success': 0, 'cached': 0,
            'failed': 0, 'timeout': 0
        }
    
    def _create_session(self):
        """åˆ›å»ºä¼˜åŒ–çš„HTTPä¼šè¯"""
        session = self.requests.Session()
        retry = self.Retry(
            total=2,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = self.HTTPAdapter(
            max_retries=retry,
            pool_connections=Config.MAX_WORKERS,
            pool_maxsize=Config.MAX_WORKERS
        )
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        session.headers.update({
            'User-Agent': Config.get_user_agent(),
            'Accept': 'text/plain, */*',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        return session
    
    def _get_cache_path(self, url: str) -> Path:
        """ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        url_hash = hashlib.md5(url.encode()).hexdigest()
        return self.cache_dir / f"cache_{url_hash}.txt"
    
    def fetch_url(self, url: str) -> Tuple[bool, Optional[str], int]:
        """è·å–URLå†…å®¹ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰"""
        cache_file = self._get_cache_path(url)
        
        # æ£€æŸ¥ç¼“å­˜
        if Config.CACHE_ENABLED and cache_file.exists():
            cache_age = time.time() - cache_file.stat().st_mtime
            if cache_age < Config.CACHE_EXPIRE_HOURS * 3600:
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = content.count('\n')
                        self.stats['cached'] += 1
                        self.stats['success'] += 1
                        return True, content, lines
                except:
                    pass  # ç¼“å­˜è¯»å–å¤±è´¥ï¼Œé‡æ–°ä¸‹è½½
        
        # ç½‘ç»œè¯·æ±‚
        try:
            start_time = time.time()
            response = self.session.get(
                url, 
                timeout=Config.REQUEST_TIMEOUT,
                stream=False
            )
            response.raise_for_status()
            
            content = response.text
            lines = content.count('\n') + 1
            elapsed = time.time() - start_time
            
            # ä¿å­˜ç¼“å­˜
            if Config.CACHE_ENABLED:
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                except:
                    pass
            
            self.stats['success'] += 1
            return True, content, lines
            
        except self.requests.exceptions.Timeout:
            self.stats['timeout'] += 1
            return False, None, 0
        except Exception as e:
            self.stats['failed'] += 1
            return False, None, 0

class MultiStageProcessor:
    """å¤šé˜¶æ®µå¤„ç†å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.stats = {
            'stage1_download': {'time': 0, 'rules': 0},
            'stage2_parse': {'time': 0, 'rules': 0},
            'stage3_dedup': {'time': 0, 'before': 0, 'after': 0},
            'stage4_optimize': {'time': 0, 'before': 0, 'after': 0},
            'stage5_secondary': {'time': 0, 'before': 0, 'after': 0},
            'stage6_output': {'time': 0, 'rules': 0},
            'total_time': 0,
            'final_rules': 0
        }
    
    def log_stage_start(self, stage_name: str):
        """è®°å½•é˜¶æ®µå¼€å§‹"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {stage_name}")
        print(f"{'='*60}")
        return time.time()
    
    def log_stage_end(self, stage_name: str, start_time: float, **kwargs):
        """è®°å½•é˜¶æ®µç»“æŸ"""
        elapsed = time.time() - start_time
        self.stats[stage_name]['time'] = elapsed
        print(f"âœ… å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
        for key, value in kwargs.items():
            if key in self.stats[stage_name]:
                self.stats[stage_name][key] = value
            print(f"   {key}: {value:,}")

class SmartRuleParser:
    """æ™ºèƒ½è§„åˆ™è§£æå™¨"""
    
    @staticmethod
    def parse_line(line: str) -> Optional[str]:
        """è§£æå•è¡Œè§„åˆ™"""
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
        if not line or (Config.SKIP_COMMENT_LINES and line[0] in '!#'):
            return None
        
        # é•¿åº¦æ£€æŸ¥
        if len(line) > Config.PARSE_MAX_LINE_LENGTH:
            return None
        
        # è§„åˆ™éªŒè¯
        if not SmartRuleParser.is_valid_rule(line):
            return None
        
        return line
    
    @staticmethod
    def is_valid_rule(rule: str) -> bool:
        """éªŒè¯è§„åˆ™æœ‰æ•ˆæ€§"""
        # æ£€æŸ¥åŸºæœ¬æ ¼å¼
        if ' ' in rule and not rule.startswith(('0.0.0.0', '127.0.0.1')):
            return False
        
        # æ£€æŸ¥åŸŸåè§„åˆ™
        if rule.startswith('||') and '^' in rule:
            domain = rule[2:].split('^')[0]
            return SmartRuleParser.is_valid_domain(domain)
        
        # æ£€æŸ¥hostsè§„åˆ™
        if rule.startswith(('0.0.0.0 ', '127.0.0.1 ')):
            parts = rule.split()
            if len(parts) >= 2:
                return SmartRuleParser.is_valid_domain(parts[1])
        
        # æ£€æŸ¥çº¯åŸŸå
        if DOMAIN_PATTERN.match(rule):
            return SmartRuleParser.is_valid_domain(rule)
        
        return True
    
    @staticmethod
    def is_valid_domain(domain: str) -> bool:
        """éªŒè¯åŸŸåæœ‰æ•ˆæ€§"""
        if not domain:
            return False
        
        length = len(domain)
        if length < Config.MIN_DOMAIN_LENGTH or length > Config.MAX_DOMAIN_LENGTH:
            return False
        
        # æ£€æŸ¥ç‰¹æ®Šå­—ç¬¦
        if '..' in domain or domain.startswith('.') or domain.endswith('.'):
            return False
        
        # æ£€æŸ¥éæ³•å­—ç¬¦
        invalid_chars = [' ', '@', '!', '#', '$', '%', '^', '&', '*', '(', ')', '=', '+', '[', ']', '{', '}', '|', '\\', ';', ':', "'", '"', '<', '>', ',', '?', '/']
        for char in invalid_chars:
            if char in domain:
                return False
        
        return True

class MultiStageDeduplicator:
    """å¤šé˜¶æ®µå»é‡å™¨"""
    
    def __init__(self):
        self.stats = {
            'stage1_hash': {'before': 0, 'after': 0},
            'stage2_domain': {'before': 0, 'after': 0},
            'stage3_subdomain': {'before': 0, 'after': 0},
            'total_removed': 0
        }
    
    def deduplicate(self, rules: List[str]) -> List[str]:
        """å¤šé˜¶æ®µå»é‡"""
        if not rules:
            return []
        
        print(f"  å¼€å§‹å¤šé˜¶æ®µå»é‡ {len(rules):,} æ¡è§„åˆ™...")
        
        current_rules = rules.copy()
        
        # ç¬¬ä¸€é˜¶æ®µï¼šå“ˆå¸Œå»é‡ï¼ˆå¿«é€Ÿï¼‰
        if Config.HASH_DEDUP_ENABLED:
            current_rules = self._hash_deduplicate(current_rules)
        
        # ç¬¬äºŒé˜¶æ®µï¼šåŸŸåçº§å»é‡
        if Config.DOMAIN_DEDUP_ENABLED:
            current_rules = self._domain_deduplicate(current_rules)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šå­åŸŸåä¼˜åŒ–
        if Config.SUBDOMAIN_OPTIMIZATION:
            current_rules = self._subdomain_optimize(current_rules)
        
        total_removed = len(rules) - len(current_rules)
        self.stats['total_removed'] = total_removed
        
        print(f"  å»é‡å®Œæˆ: {len(current_rules):,} æ¡ (ç§»é™¤ {total_removed:,} æ¡)")
        
        return current_rules
    
    def _hash_deduplicate(self, rules: List[str]) -> List[str]:
        """å“ˆå¸Œå»é‡ï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰"""
        start_time = time.time()
        before = len(rules)
        
        seen = set()
        unique_rules = []
        
        for rule in rules:
            rule_hash = hashlib.md5(rule.encode()).hexdigest()
            if rule_hash not in seen:
                seen.add(rule_hash)
                unique_rules.append(rule)
        
        after = len(unique_rules)
        elapsed = time.time() - start_time
        
        self.stats['stage1_hash']['before'] = before
        self.stats['stage1_hash']['after'] = after
        
        print(f"    ğŸ¯ å“ˆå¸Œå»é‡: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return unique_rules
    
    def _domain_deduplicate(self, rules: List[str]) -> List[str]:
        """åŸŸåçº§å»é‡ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰"""
        start_time = time.time()
        before = len(rules)
        
        # åˆ†ç¦»ä¸åŒç±»å‹è§„åˆ™
        domain_rules = {}
        other_rules = []
        
        for rule in rules:
            domain = self._extract_domain(rule)
            if domain:
                # æ¯ä¸ªåŸŸååªä¿ç•™ä¸€æ¡è§„åˆ™ï¼ˆä¼˜å…ˆä¿ç•™æ›´é€šç”¨çš„ï¼‰
                if domain not in domain_rules:
                    domain_rules[domain] = rule
                else:
                    # å¦‚æœæ–°è§„åˆ™æ›´é€šç”¨ï¼ˆæ›´çŸ­æˆ–åŒ…å«é€šé…ç¬¦ï¼‰ï¼Œåˆ™æ›¿æ¢
                    existing = domain_rules[domain]
                    if self._is_more_general(rule, existing):
                        domain_rules[domain] = rule
            else:
                other_rules.append(rule)
        
        # åˆå¹¶ç»“æœ
        result = list(domain_rules.values()) + other_rules
        after = len(result)
        elapsed = time.time() - start_time
        
        self.stats['stage2_domain']['before'] = before
        self.stats['stage2_domain']['after'] = after
        
        print(f"    ğŸ¯ åŸŸåå»é‡: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return result
    
    def _subdomain_optimize(self, rules: List[str]) -> List[str]:
        """å­åŸŸåä¼˜åŒ–ï¼ˆç¬¬ä¸‰é˜¶æ®µï¼‰"""
        if len(rules) < 10000:  # è§„åˆ™è¾ƒå°‘æ—¶è·³è¿‡
            return rules
        
        start_time = time.time()
        before = len(rules)
        
        # æå–åŸŸåè§„åˆ™
        domain_to_rule = {}
        other_rules = []
        
        for rule in rules:
            domain = self._extract_domain(rule)
            if domain:
                domain_to_rule[domain] = rule
            else:
                other_rules.append(rule)
        
        # æ„å»ºåŸŸåæ ‘
        domain_tree = {}
        for domain in domain_to_rule.keys():
            parts = domain.split('.')
            current = domain_tree
            for part in reversed(parts):
                if part not in current:
                    current[part] = {}
                current = current[part]
        
        # ä¼˜åŒ–ï¼šç§»é™¤ä¸å¿…è¦çš„å­åŸŸå
        optimized_domains = set()
        for domain in domain_to_rule.keys():
            parts = domain.split('.')
            current = domain_tree
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å…¶ä»–åŸŸåçš„å­åŸŸå
            is_subdomain = False
            for i in range(1, len(parts)):
                parent = '.'.join(parts[i:])
                if parent in domain_to_rule:
                    is_subdomain = True
                    break
            
            if not is_subdomain:
                optimized_domains.add(domain)
        
        # æ„å»ºç»“æœ
        result = [domain_to_rule[d] for d in optimized_domains] + other_rules
        after = len(result)
        elapsed = time.time() - start_time
        
        self.stats['stage3_subdomain']['before'] = before
        self.stats['stage3_subdomain']['after'] = after
        
        print(f"    ğŸ¯ å­åŸŸåä¼˜åŒ–: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return result
    
    def _extract_domain(self, rule: str) -> Optional[str]:
        """ä»è§„åˆ™ä¸­æå–åŸŸå"""
        if rule.startswith('||') and '^' in rule:
            return rule[2:].split('^')[0]
        elif rule.startswith(('0.0.0.0 ', '127.0.0.1 ')):
            parts = rule.split()
            if len(parts) >= 2:
                return parts[1]
        elif DOMAIN_PATTERN.match(rule):
            return rule
        return None
    
    def _is_more_general(self, rule1: str, rule2: str) -> bool:
        """åˆ¤æ–­rule1æ˜¯å¦æ¯”rule2æ›´é€šç”¨"""
        # è§„åˆ™1åŒ…å«é€šé…ç¬¦è€Œè§„åˆ™2ä¸åŒ…å«
        if '*' in rule1 and '*' not in rule2:
            return True
        
        # è§„åˆ™1æ˜¯åŸŸåè§„åˆ™ï¼ˆ||domain^ï¼‰è€Œè§„åˆ™2æ˜¯æ›´å…·ä½“çš„è§„åˆ™
        if rule1.startswith('||') and not rule2.startswith('||'):
            return True
        
        # è§„åˆ™1æ¯”è§„åˆ™2çŸ­ï¼ˆé€šå¸¸æ›´é€šç”¨ï¼‰
        if len(rule1) < len(rule2):
            return True
        
        return False

class AdvancedRuleOptimizer:
    """é«˜çº§è§„åˆ™ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.stats = {
            'by_priority': 0,
            'by_validation': 0,
            'by_quality': 0,
            'total_removed': 0
        }
    
    def optimize(self, rules: List[str]) -> List[str]:
        """ä¼˜åŒ–è§„åˆ™"""
        if not rules:
            return []
        
        print(f"  å¼€å§‹ä¼˜åŒ– {len(rules):,} æ¡è§„åˆ™...")
        
        current_rules = rules.copy()
        
        # 1. æŒ‰ä¼˜å…ˆçº§è¿‡æ»¤
        if Config.MIN_RULE_PRIORITY > 0:
            current_rules = self._filter_by_priority(current_rules)
        
        # 2. è§„åˆ™éªŒè¯
        if Config.ENABLE_RULE_VALIDATION:
            current_rules = self._validate_rules(current_rules)
        
        # 3. è´¨é‡è¿‡æ»¤
        current_rules = self._filter_by_quality(current_rules)
        
        # 4. åˆ†ç±»å’Œé™åˆ¶
        current_rules = self._classify_and_limit(current_rules)
        
        total_removed = len(rules) - len(current_rules)
        self.stats['total_removed'] = total_removed
        
        print(f"  ä¼˜åŒ–å®Œæˆ: {len(current_rules):,} æ¡ (ç§»é™¤ {total_removed:,} æ¡)")
        
        return current_rules
    
    def _filter_by_priority(self, rules: List[str]) -> List[str]:
        """æŒ‰ä¼˜å…ˆçº§è¿‡æ»¤"""
        start_time = time.time()
        before = len(rules)
        
        filtered_rules = []
        for rule in rules:
            score = Config.get_priority_score(rule)
            if score >= Config.MIN_RULE_PRIORITY:
                filtered_rules.append(rule)
        
        after = len(filtered_rules)
        elapsed = time.time() - start_time
        
        self.stats['by_priority'] = before - after
        print(f"    ğŸ¯ ä¼˜å…ˆçº§è¿‡æ»¤: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return filtered_rules
    
    def _validate_rules(self, rules: List[str]) -> List[str]:
        """éªŒè¯è§„åˆ™æœ‰æ•ˆæ€§"""
        start_time = time.time()
        before = len(rules)
        
        valid_rules = []
        for rule in rules:
            if SmartRuleParser.is_valid_rule(rule):
                valid_rules.append(rule)
        
        after = len(valid_rules)
        elapsed = time.time() - start_time
        
        self.stats['by_validation'] = before - after
        print(f"    ğŸ¯ è§„åˆ™éªŒè¯: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return valid_rules
    
    def _filter_by_quality(self, rules: List[str]) -> List[str]:
        """æŒ‰è´¨é‡è¿‡æ»¤"""
        start_time = time.time()
        before = len(rules)
        
        quality_rules = []
        for rule in rules:
            # è·³è¿‡æ˜æ˜¾ä½è´¨é‡çš„è§„åˆ™
            if self._is_low_quality(rule):
                continue
            quality_rules.append(rule)
        
        after = len(quality_rules)
        elapsed = time.time() - start_time
        
        self.stats['by_quality'] = before - after
        print(f"    ğŸ¯ è´¨é‡è¿‡æ»¤: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return quality_rules
    
    def _is_low_quality(self, rule: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºä½è´¨é‡è§„åˆ™"""
        # è§„åˆ™è¿‡é•¿æˆ–è¿‡çŸ­
        if len(rule) < 3 or len(rule) > 500:
            return True
        
        # åŒ…å«è¿‡å¤šç‰¹æ®Šå­—ç¬¦
        special_chars = ['*', '^', '|', '#', '!']
        char_count = sum(1 for char in rule if char in special_chars)
        if char_count > 5:
            return True
        
        # ç–‘ä¼¼æ— æ•ˆçš„åŸŸå
        if rule.startswith('||') and '^' in rule:
            domain = rule[2:].split('^')[0]
            if len(domain.split('.')) > 5:  # è¿‡å¤šå­åŸŸå
                return True
        
        return False
    
    def _classify_and_limit(self, rules: List[str]) -> List[str]:
        """åˆ†ç±»å¹¶åº”ç”¨æ•°é‡é™åˆ¶"""
        start_time = time.time()
        
        # åˆ†ç±»
        adblock_rules = []
        hosts_rules = []
        domain_rules = []
        
        for rule in rules:
            if rule.startswith('||') or '##' in rule or rule.startswith('|'):
                adblock_rules.append(rule)
            elif rule.startswith('0.0.0.0') or rule.startswith('127.0.0.1'):
                hosts_rules.append(rule)
            elif DOMAIN_PATTERN.match(rule):
                domain_rules.append(rule)
        
        # åº”ç”¨é™åˆ¶
        adblock_rules = adblock_rules[:Config.MAX_ADBLOCK_RULES]
        hosts_rules = hosts_rules[:Config.MAX_HOSTS_RULES]
        domain_rules = domain_rules[:Config.MAX_DOMAIN_RULES]
        
        # åˆå¹¶
        result = adblock_rules + hosts_rules + domain_rules
        result = result[:Config.MAX_TOTAL_RULES]
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        if Config.SORT_BY_PRIORITY:
            result.sort(key=lambda x: Config.get_priority_score(x), reverse=True)
        
        # æŒ‰é•¿åº¦æ’åº
        if Config.SORT_BY_LENGTH:
            result.sort(key=lambda x: len(x))
        
        elapsed = time.time() - start_time
        
        print(f"    ğŸ¯ åˆ†ç±»é™åˆ¶:")
        print(f"      Adblock: {len(adblock_rules):,}/{Config.MAX_ADBLOCK_RULES:,}")
        print(f"      Hosts: {len(hosts_rules):,}/{Config.MAX_HOSTS_RULES:,}")
        print(f"      åŸŸå: {len(domain_rules):,}/{Config.MAX_DOMAIN_RULES:,}")
        print(f"      æ€»è®¡: {len(result):,}/{Config.MAX_TOTAL_RULES:,}")
        print(f"      è€—æ—¶: {elapsed:.2f}s")
        
        return result

class SecondaryOptimizer:
    """äºŒæ¬¡ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.stats = {
            'expired_removed': 0,
            'similar_merged': 0,
            'total_removed': 0
        }
    
    def optimize(self, rules: List[str]) -> List[str]:
        """äºŒæ¬¡ä¼˜åŒ–"""
        if not Config.ENABLE_SECONDARY_OPTIMIZATION or len(rules) < 1000:
            return rules
        
        print(f"  å¼€å§‹äºŒæ¬¡ä¼˜åŒ– {len(rules):,} æ¡è§„åˆ™...")
        
        current_rules = rules.copy()
        
        # 1. ç§»é™¤è¿‡æœŸ/å¤±æ•ˆè§„åˆ™
        if Config.REMOVE_EXPIRED_DOMAINS:
            current_rules = self._remove_expired_domains(current_rules)
        
        # 2. åˆå¹¶ç›¸ä¼¼è§„åˆ™
        if Config.MERGE_SIMILAR_RULES:
            current_rules = self._merge_similar_rules(current_rules)
        
        total_removed = len(rules) - len(current_rules)
        self.stats['total_removed'] = total_removed
        
        print(f"  äºŒæ¬¡ä¼˜åŒ–å®Œæˆ: {len(current_rules):,} æ¡ (ç§»é™¤ {total_removed:,} æ¡)")
        
        return current_rules
    
    def _remove_expired_domains(self, rules: List[str]) -> List[str]:
        """ç§»é™¤è¿‡æœŸåŸŸå"""
        start_time = time.time()
        before = len(rules)
        
        # å¸¸è§è¿‡æœŸåŸŸåæ¨¡å¼
        expired_patterns = [
            r'\d{8,}',  # åŒ…å«8ä½ä»¥ä¸Šæ•°å­—ï¼ˆå¯èƒ½æ˜¯æ—¥æœŸï¼‰
            r'20\d{2}[01]\d[0-3]\d',  # æ—¥æœŸæ ¼å¼
            r'expired', r'old', r'dead', r'invalid',
            r'test', r'example', r'dummy'
        ]
        
        filtered_rules = []
        for rule in rules:
            skip = False
            for pattern in expired_patterns:
                if re.search(pattern, rule, re.IGNORECASE):
                    skip = True
                    break
            if not skip:
                filtered_rules.append(rule)
        
        after = len(filtered_rules)
        elapsed = time.time() - start_time
        
        self.stats['expired_removed'] = before - after
        print(f"    ğŸ¯ ç§»é™¤è¿‡æœŸåŸŸå: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return filtered_rules
    
    def _merge_similar_rules(self, rules: List[str]) -> List[str]:
        """åˆå¹¶ç›¸ä¼¼è§„åˆ™"""
        if len(rules) < 5000:  # è§„åˆ™è¾ƒå°‘æ—¶è·³è¿‡
            return rules
        
        start_time = time.time()
        before = len(rules)
        
        # æŒ‰è§„åˆ™ç±»å‹åˆ†ç»„
        adblock_groups = defaultdict(list)
        hosts_groups = defaultdict(list)
        domain_groups = defaultdict(list)
        other_rules = []
        
        for rule in rules:
            if rule.startswith('||') and '^' in rule:
                domain = rule[2:].split('^')[0]
                base_domain = '.'.join(domain.split('.')[-2:])  # å–ä¸»åŸŸå
                adblock_groups[base_domain].append(rule)
            elif rule.startswith(('0.0.0.0 ', '127.0.0.1 ')):
                parts = rule.split()
                if len(parts) >= 2:
                    domain = parts[1]
                    base_domain = '.'.join(domain.split('.')[-2:])
                    hosts_groups[base_domain].append(rule)
            elif DOMAIN_PATTERN.match(rule):
                base_domain = '.'.join(rule.split('.')[-2:])
                domain_groups[base_domain].append(rule)
            else:
                other_rules.append(rule)
        
        # åˆå¹¶æ¯ç»„ä¸­çš„è§„åˆ™ï¼ˆé€‰æ‹©æœ€ä¼˜çš„ä¸€æ¡ï¼‰
        merged_rules = []
        
        for group in [adblock_groups, hosts_groups, domain_groups]:
            for base_domain, group_rules in group.items():
                if len(group_rules) == 1:
                    merged_rules.append(group_rules[0])
                else:
                    # é€‰æ‹©æœ€ä¼˜çš„è§„åˆ™ï¼ˆæœ€çŸ­çš„æˆ–åŒ…å«é€šé…ç¬¦çš„ï¼‰
                    best_rule = min(group_rules, key=lambda x: (
                        len(x),
                        0 if '*' in x else 1  # ä¼˜å…ˆé€‰æ‹©åŒ…å«é€šé…ç¬¦çš„
                    ))
                    merged_rules.append(best_rule)
        
        merged_rules.extend(other_rules)
        after = len(merged_rules)
        elapsed = time.time() - start_time
        
        self.stats['similar_merged'] = before - after
        print(f"    ğŸ¯ åˆå¹¶ç›¸ä¼¼è§„åˆ™: {before:,} â†’ {after:,} æ¡ (-{before-after:,}), è€—æ—¶: {elapsed:.2f}s")
        
        return merged_rules

class RuleOutputManager:
    """è§„åˆ™è¾“å‡ºç®¡ç†å™¨"""
    
    @staticmethod
    def save_results(rules: List[str]) -> bool:
        """ä¿å­˜ä¼˜åŒ–åçš„è§„åˆ™"""
        try:
            os.makedirs("dist", exist_ok=True)
            os.makedirs("stats", exist_ok=True)
            
            current_time = get_time_string()
            
            # åˆ†ç±»è§„åˆ™
            adblock_rules = []
            hosts_rules = []
            domain_rules = []
            
            for rule in rules:
                if rule.startswith('||') or '##' in rule or rule.startswith('|'):
                    adblock_rules.append(rule)
                elif rule.startswith('0.0.0.0') or rule.startswith('127.0.0.1'):
                    hosts_rules.append(rule)
                elif DOMAIN_PATTERN.match(rule):
                    domain_rules.append(rule)
            
            # ä¿å­˜Adblockè§„åˆ™
            if adblock_rules:
                RuleOutputManager._save_adblock_rules(adblock_rules, current_time)
            
            # ä¿å­˜Hostsè§„åˆ™
            if hosts_rules:
                RuleOutputManager._save_hosts_rules(hosts_rules, current_time)
            
            # ä¿å­˜åŸŸåè§„åˆ™
            if domain_rules:
                RuleOutputManager._save_domain_rules(domain_rules, current_time)
            
            print(f"  ğŸ’¾ æ€»è®¡ä¿å­˜: {len(rules):,} æ¡è§„åˆ™")
            return True
            
        except Exception as e:
            print(f"  âŒ ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    @staticmethod
    def _save_adblock_rules(rules: List[str], current_time: str):
        """ä¿å­˜Adblockè§„åˆ™"""
        file_path = "dist/Adblock.txt"
        batch_size = Config.BATCH_PROCESS_SIZE
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"""! Adblockè§„åˆ™ - å¤šé˜¶æ®µä¼˜åŒ–ç‰ˆ
! ç”Ÿæˆæ—¶é—´: {current_time}
! è§„åˆ™æ•°é‡: {len(rules):,}
! é¡¹ç›®åœ°å€: https://github.com/{Config.REPO_OWNER}/{Config.REPO_NAME}
! ä¼˜åŒ–æµç¨‹: ä¸‹è½½ â†’ è§£æ â†’ å»é‡ â†’ ä¼˜åŒ– â†’ äºŒæ¬¡ä¼˜åŒ– â†’ è¾“å‡º
!

""")
            # æ‰¹é‡å†™å…¥
            for i in range(0, len(rules), batch_size):
                batch = rules[i:i+batch_size]
                f.write('\n'.join(batch) + '\n')
        
        file_size = os.path.getsize(file_path) / (1024 * 1024)
        print(f"  âœ… Adblockè§„åˆ™: {len(rules):,} æ¡ ({file_size:.2f} MB)")
    
    @staticmethod
    def _save_hosts_rules(rules: List[str], current_time: str):
        """ä¿å­˜Hostsè§„åˆ™"""
        file_path = "dist/hosts.txt"
        batch_size = Config.BATCH_PROCESS_SIZE
        
        # åˆ†ç¦»0.0.0.0å’Œ127.0.0.1
        zero_rules = [r for r in rules if r.startswith('0.0.0.0')]
        local_rules = [r for r in rules if r.startswith('127.0.0.1')]
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"""# Hostsè§„åˆ™ - å¤šé˜¶æ®µä¼˜åŒ–ç‰ˆ
# ç”Ÿæˆæ—¶é—´: {current_time}
# è§„åˆ™æ•°é‡: {len(rules):,} (0.0.0.0: {len(zero_rules):,}, 127.0.0.1: {len(local_rules):,})
# é¡¹ç›®åœ°å€: https://github.com/{Config.REPO_OWNER}/{Config.REPO_NAME}
#

""")
            # å†™å…¥0.0.0.0è§„åˆ™
            if zero_rules:
                for i in range(0, len(zero_rules), batch_size):
                    batch = zero_rules[i:i+batch_size]
                    f.write('\n'.join(batch) + '\n')
            
            # å†™å…¥127.0.0.1è§„åˆ™
            if local_rules:
                f.write('\n')
                for i in range(0, len(local_rules), batch_size):
                    batch = local_rules[i:i+batch_size]
                    f.write('\n'.join(batch) + '\n')
        
        file_size = os.path.getsize(file_path) / (1024 * 1024)
        print(f"  âœ… Hostsè§„åˆ™: {len(rules):,} æ¡ ({file_size:.2f} MB)")
    
    @staticmethod
    def _save_domain_rules(rules: List[str], current_time: str):
        """ä¿å­˜åŸŸåè§„åˆ™"""
        file_path = "dist/Domains.txt"
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"""# åŸŸåè§„åˆ™ - å¤šé˜¶æ®µä¼˜åŒ–ç‰ˆ
# ç”Ÿæˆæ—¶é—´: {current_time}
# åŸŸåæ•°é‡: {len(rules):,}
# é¡¹ç›®åœ°å€: https://github.com/{Config.REPO_OWNER}/{Config.REPO_NAME}
#

""")
            # æŒ‰å­—æ¯é¡ºåºæ’åº
            sorted_rules = sorted(rules)
            for rule in sorted_rules:
                f.write(f"{rule}\n")
        
        file_size = os.path.getsize(file_path) / (1024 * 1024)
        print(f"  âœ… åŸŸåè§„åˆ™: {len(rules):,} æ¡ ({file_size:.2f} MB)")

class SmartRuleProcessor:
    """æ™ºèƒ½è§„åˆ™å¤„ç†å™¨ï¼ˆå¤šé˜¶æ®µä¼˜åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        self.fetcher = AdvancedRuleFetcher()
        self.multi_stage = MultiStageProcessor()
        self.parser = SmartRuleParser()
        self.deduplicator = MultiStageDeduplicator()
        self.optimizer = AdvancedRuleOptimizer()
        self.secondary_optimizer = SecondaryOptimizer()
        self.output_manager = RuleOutputManager()
        
        # åŠ è½½è§„åˆ™æº
        try:
            sources = get_all_sources()
            self.rule_sources = sources
        except:
            self.rule_sources = [
                "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt",
                "https://easylist.to/easylist/easylist.txt",
                "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",
                "https://someonewhocares.org/hosts/hosts",
            ]
        
        self.all_rules = []
        self.final_rules = []
        
    def process(self) -> bool:
        """ä¸»å¤„ç†æµç¨‹"""
        print("=" * 70)
        print("ğŸš€ å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ - å¤šé˜¶æ®µä¼˜åŒ–ç‰ˆ")
        print(f"ğŸ“… å¼€å§‹æ—¶é—´: {get_time_string()}")
        print(f"ğŸ“Š è§„åˆ™æº: {len(self.rule_sources)} ä¸ª")
        print(f"âš™ï¸  é…ç½®: å¹¶å‘={Config.MAX_WORKERS}, è¶…æ—¶={Config.REQUEST_TIMEOUT}s")
        print("=" * 70)
        
        # è®¾ç½®æ€»è¶…æ—¶
        signal.alarm(Config.TIMEOUT_FORCE_STOP + 60)
        
        try:
            # é˜¶æ®µ1ï¼šä¸‹è½½
            stage_start = self.multi_stage.log_stage_start("é˜¶æ®µ1: ä¸‹è½½è§„åˆ™æº")
            contents = self._download_sources()
            self.multi_stage.log_stage_end('stage1_download', stage_start, rules=len(contents))
            
            if self._check_timeout():
                return False
            
            # é˜¶æ®µ2ï¼šè§£æ
            stage_start = self.multi_stage.log_stage_start("é˜¶æ®µ2: è§£æè§„åˆ™")
            self._parse_contents(contents)
            self.multi_stage.log_stage_end('stage2_parse', stage_start, rules=len(self.all_rules))
            
            if self._check_timeout():
                return False
            
            # é˜¶æ®µ3ï¼šå¤šé˜¶æ®µå»é‡
            stage_start = self.multi_stage.log_stage_start("é˜¶æ®µ3: å¤šé˜¶æ®µå»é‡")
            deduplicated_rules = self.deduplicator.deduplicate(self.all_rules)
            self.multi_stage.log_stage_end('stage3_dedup', stage_start, 
                                          before=len(self.all_rules), 
                                          after=len(deduplicated_rules))
            
            if self._check_timeout():
                return False
            
            # é˜¶æ®µ4ï¼šä¼˜åŒ–
            stage_start = self.multi_stage.log_stage_start("é˜¶æ®µ4: è§„åˆ™ä¼˜åŒ–")
            optimized_rules = self.optimizer.optimize(deduplicated_rules)
            self.multi_stage.log_stage_end('stage4_optimize', stage_start,
                                          before=len(deduplicated_rules),
                                          after=len(optimized_rules))
            
            if self._check_timeout():
                return False
            
            # é˜¶æ®µ5ï¼šäºŒæ¬¡ä¼˜åŒ–
            stage_start = self.multi_stage.log_stage_start("é˜¶æ®µ5: äºŒæ¬¡ä¼˜åŒ–")
            final_rules = self.secondary_optimizer.optimize(optimized_rules)
            self.multi_stage.log_stage_end('stage5_secondary', stage_start,
                                          before=len(optimized_rules),
                                          after=len(final_rules))
            
            self.final_rules = final_rules
            
            if self._check_timeout():
                return False
            
            # é˜¶æ®µ6ï¼šè¾“å‡º
            stage_start = self.multi_stage.log_stage_start("é˜¶æ®µ6: ä¿å­˜ç»“æœ")
            success = self.output_manager.save_results(final_rules)
            self.multi_stage.log_stage_end('stage6_output', stage_start, rules=len(final_rules))
            
            # ç”ŸæˆæŠ¥å‘Š
            self._generate_final_report(success)
            
            signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
            return success
            
        except TimeoutException:
            print("\nâ° å¤„ç†è¶…æ—¶ï¼Œä¿å­˜å·²å¤„ç†çš„æ•°æ®...")
            self._save_partial_results()
            return False
        except Exception as e:
            print(f"\nâŒ å¤„ç†å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _check_timeout(self):
        """æ£€æŸ¥æ˜¯å¦è¶…æ—¶"""
        elapsed = time.time() - self.multi_stage.start_time
        if elapsed > Config.TIMEOUT_FORCE_STOP:
            print(f"â° è¶…æ—¶ä¿æŠ¤è§¦å‘ï¼šå·²è¿è¡Œ {elapsed:.0f} ç§’")
            return True
        return False
    
    def _download_sources(self) -> Dict[str, str]:
        """ä¸‹è½½æ‰€æœ‰è§„åˆ™æº"""
        contents = {}
        max_workers = min(Config.MAX_WORKERS, len(self.rule_sources))
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(self.fetcher.fetch_url, url): url 
                      for url in self.rule_sources}
            
            completed = 0
            total = len(self.rule_sources)
            
            for future in as_completed(futures):
                url = futures[future]
                success, content, lines = future.result()
                completed += 1
                
                if success and content:
                    contents[url] = content
                    if completed % 5 == 0:
                        print(f"  [{completed}/{total}] {lines:6d} è¡Œ")
                else:
                    if completed % 5 == 0:
                        print(f"  [{completed}/{total}] å¤±è´¥")
        
        print(f"âœ… ä¸‹è½½ç»Ÿè®¡: {len(contents)}æˆåŠŸ, {self.fetcher.stats['failed']}å¤±è´¥, "
              f"{self.fetcher.stats['cached']}ç¼“å­˜")
        return contents
    
    def _parse_contents(self, contents: Dict[str, str]):
        """è§£ææ‰€æœ‰å†…å®¹"""
        rule_count = 0
        
        for url, content in contents.items():
            lines = content.split('\n')
            for line in lines:
                parsed = self.parser.parse_line(line)
                if parsed:
                    self.all_rules.append(parsed)
                    rule_count += 1
                
                # å®šæœŸæ£€æŸ¥è¶…æ—¶
                if rule_count % 500000 == 0:
                    print(f"  å·²è§£æ {rule_count:,} æ¡è§„åˆ™")
                    if self._check_timeout():
                        return
        
        print(f"âœ… è§£æå®Œæˆ: {rule_count:,} æ¡åŸå§‹è§„åˆ™")
    
    def _save_partial_results(self):
        """ä¿å­˜éƒ¨åˆ†ç»“æœï¼ˆè¶…æ—¶æƒ…å†µä¸‹ï¼‰"""
        try:
            if self.final_rules:
                # ä¿å­˜æœ€ç»ˆè§„åˆ™
                self.output_manager.save_results(self.final_rules)
            elif self.all_rules:
                # ä¿å­˜è§£æåçš„è§„åˆ™
                os.makedirs("dist", exist_ok=True)
                with open("dist/partial_rules.txt", 'w', encoding='utf-8') as f:
                    f.write(f"! éƒ¨åˆ†è§„åˆ™ (è¶…æ—¶ä¿æŠ¤)\n")
                    f.write(f"! ç”Ÿæˆæ—¶é—´: {get_time_string()}\n")
                    f.write(f"! è§„åˆ™æ•°é‡: {len(self.all_rules):,}\n!\n\n")
                    f.write('\n'.join(self.all_rules[:100000]))
                
                print(f"  âš ï¸  å·²ä¿å­˜éƒ¨åˆ†è§„åˆ™ ({len(self.all_rules):,} æ¡)")
        except:
            pass
    
    def _generate_final_report(self, success: bool):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        try:
            elapsed = time.time() - self.multi_stage.start_time
            self.multi_stage.stats['total_time'] = elapsed
            self.multi_stage.stats['final_rules'] = len(self.final_rules)
            
            # åˆå¹¶æ‰€æœ‰ç»Ÿè®¡
            full_stats = {
                'processing_info': {
                    'start_time': get_time_string(),
                    'total_duration_seconds': round(elapsed, 2),
                    'status': 'success' if success else 'partial',
                    'timestamp': datetime.now().isoformat()
                },
                'stage_statistics': self.multi_stage.stats,
                'deduplication_stats': self.deduplicator.stats,
                'optimization_stats': self.optimizer.stats,
                'secondary_optimization_stats': self.secondary_optimizer.stats,
                'download_stats': self.fetcher.stats,
                'final_counts': {
                    'adblock_rules': len([r for r in self.final_rules if r.startswith('||') or '##' in r or r.startswith('|')]),
                    'hosts_rules': len([r for r in self.final_rules if r.startswith('0.0.0.0') or r.startswith('127.0.0.1')]),
                    'domain_rules': len([r for r in self.final_rules if DOMAIN_PATTERN.match(r)]),
                    'total_rules': len(self.final_rules)
                },
                'configuration': {
                    'max_workers': Config.MAX_WORKERS,
                    'request_timeout': Config.REQUEST_TIMEOUT,
                    'cache_enabled': Config.CACHE_ENABLED,
                    'max_adblock_rules': Config.MAX_ADBLOCK_RULES,
                    'max_hosts_rules': Config.MAX_HOSTS_RULES,
                    'max_domain_rules': Config.MAX_DOMAIN_RULES,
                    'max_total_rules': Config.MAX_TOTAL_RULES
                }
            }
            
            # ä¿å­˜JSONæŠ¥å‘Š
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            stats_file = f"stats/processing_stats_{timestamp}.json"
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(full_stats, f, indent=2, ensure_ascii=False)
            
            # ç”ŸæˆMarkdownæŠ¥å‘Š
            self._generate_markdown_report(full_stats, timestamp)
            
            # æ‰“å°æœ€ç»ˆæ€»ç»“
            print(f"\n{'='*70}")
            print(f"{'âœ… å¤„ç†æˆåŠŸ' if success else 'âš ï¸  éƒ¨åˆ†å®Œæˆ'}")
            print(f"{'='*70}")
            print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.2f} ç§’")
            print(f"ğŸ“Š æœ€ç»ˆè§„åˆ™: {len(self.final_rules):,} æ¡")
            print(f"ğŸ“¥ ä¸‹è½½ç»Ÿè®¡: {self.fetcher.stats['success']}æˆåŠŸ "
                  f"({self.fetcher.stats['cached']}ç¼“å­˜)")
            print(f"ğŸ“ˆ å»é‡æ•ˆæœ: {self.deduplicator.stats['total_removed']:,} æ¡å·²ç§»é™¤")
            print(f"ğŸ“ˆ ä¼˜åŒ–æ•ˆæœ: {self.optimizer.stats['total_removed']:,} æ¡å·²ç§»é™¤")
            print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {stats_file}")
            
        except Exception as e:
            print(f"  âš ï¸  æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    
    def _generate_markdown_report(self, stats_data, timestamp):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        try:
            md_file = f"stats/report_{timestamp}.md"
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(f"# å¹¿å‘Šè§„åˆ™å¤„ç†æŠ¥å‘Š - å¤šé˜¶æ®µä¼˜åŒ–ç‰ˆ\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {stats_data['processing_info']['start_time']}\n")
                f.write(f"**å¤„ç†çŠ¶æ€**: {stats_data['processing_info']['status']}\n")
                f.write(f"**æ€»è€—æ—¶**: {stats_data['processing_info']['total_duration_seconds']}ç§’\n\n")
                
                f.write(f"## ğŸ“Š æœ€ç»ˆç»Ÿè®¡\n\n")
                f.write(f"- **æ€»è§„åˆ™æ•°**: {stats_data['final_counts']['total_rules']:,} æ¡\n")
                f.write(f"- **Adblockè§„åˆ™**: {stats_data['final_counts']['adblock_rules']:,} æ¡\n")
                f.write(f"- **Hostsè§„åˆ™**: {stats_data['final_counts']['hosts_rules']:,} æ¡\n")
                f.write(f"- **åŸŸåè§„åˆ™**: {stats_data['final_counts']['domain_rules']:,} æ¡\n\n")
                
                f.write(f"## ğŸ“ˆ å¤„ç†æ•ˆæœ\n\n")
                f.write(f"- **å»é‡ç§»é™¤**: {stats_data['deduplication_stats']['total_removed']:,} æ¡\n")
                f.write(f"- **ä¼˜åŒ–ç§»é™¤**: {stats_data['optimization_stats']['total_removed']:,} æ¡\n")
                f.write(f"- **äºŒæ¬¡ä¼˜åŒ–ç§»é™¤**: {stats_data['secondary_optimization_stats']['total_removed']:,} æ¡\n\n")
                
                f.write(f"## âš™ï¸ å¤„ç†é…ç½®\n\n")
                f.write(f"- **æœ€å¤§å¹¶å‘æ•°**: {stats_data['configuration']['max_workers']}\n")
                f.write(f"- **è¯·æ±‚è¶…æ—¶**: {stats_data['configuration']['request_timeout']}ç§’\n")
                f.write(f"- **ç¼“å­˜å¯ç”¨**: {stats_data['configuration']['cache_enabled']}\n")
                f.write(f"- **Adblockä¸Šé™**: {stats_data['configuration']['max_adblock_rules']:,} æ¡\n")
                f.write(f"- **Hostsä¸Šé™**: {stats_data['configuration']['max_hosts_rules']:,} æ¡\n")
                f.write(f"- **åŸŸåä¸Šé™**: {stats_data['configuration']['max_domain_rules']:,} æ¡\n")
                f.write(f"- **æ€»è§„åˆ™ä¸Šé™**: {stats_data['configuration']['max_total_rules']:,} æ¡\n\n")
                
                f.write(f"## ğŸ“ ç”Ÿæˆæ–‡ä»¶\n\n")
                f.write(f"- [Adblock.txt](dist/Adblock.txt)\n")
                f.write(f"- [hosts.txt](dist/hosts.txt)\n")
                f.write(f"- [Domains.txt](dist/Domains.txt)\n")
                f.write(f"- [å®Œæ•´ç»Ÿè®¡æŠ¥å‘Š]({md_file})\n\n")
                
                f.write(f"---\n")
                f.write(f"*æŠ¥å‘Šç”±æ™ºèƒ½å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–ç³»ç»Ÿç”Ÿæˆ*\n")
            
            print(f"  ğŸ“‹ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")
        except Exception as e:
            print(f"  âš ï¸  MarkdownæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ å¯åŠ¨å¹¿å‘Šè§„åˆ™è‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ")
    
    def interrupt_handler(sig, frame):
        print("\n\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å½“å‰è¿›åº¦...")
        sys.exit(130)
    
    signal.signal(signal.SIGINT, interrupt_handler)
    
    try:
        processor = SmartRuleProcessor()
        success = processor.process()
        
        return 0 if success else 1
        
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        signal.alarm(0)  # ç¡®ä¿å–æ¶ˆæ‰€æœ‰è¶…æ—¶

if __name__ == "__main__":
    sys.exit(main())
